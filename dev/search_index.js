var documenterSearchIndex = {"docs":
[{"location":"reference/function_reference/#Filtering-functions","page":"Function reference","title":"Filtering functions","text":"","category":"section"},{"location":"reference/function_reference/#Functions","page":"Function reference","title":"Functions","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"imfilter\nimfilter!\nimgradients\nmapwindow\nmapwindow!","category":"page"},{"location":"reference/function_reference/#ImageFiltering.imfilter","page":"Function reference","title":"ImageFiltering.imfilter","text":"imfilter([T], img, kernel, [border=\"replicate\"], [alg]) --> imgfilt\nimfilter([r], img, kernel, [border=\"replicate\"], [alg]) --> imgfilt\nimfilter(r, T, img, kernel, [border=\"replicate\"], [alg]) --> imgfilt\n\nFilter a one, two or multidimensional array img with a kernel by computing their correlation.\n\nExtended help\n\nChoices for r\n\nOptionally, you can dispatch to different implementations by passing in a resource r as defined by the ComputationalResources package.\n\nFor example:\n\nimfilter(ArrayFireLibs(), img, kernel)\n\nwould request that the computation be performed on the GPU using the ArrayFire libraries.\n\nChoices for T\n\nOptionally, you can control the element type of the output image by passing in a type T as the first argument.\n\nChoices for img\n\nYou can specify a one, two, or multidimensional array defining your image.\n\nChoices for kernel\n\nThe kernel[0, 0,..] parameter corresponds to the origin (zero displacement) of the kernel; you can use centered to place the origin at the array center, or use the OffsetArrays package to set kernel's indices manually. For example, to filter with a random centered 3x3 kernel, you could use either of the following:\n\nkernel = centered(rand(3,3))\nkernel = OffsetArray(rand(3,3), -1:1, -1:1)\n\nThe kernel parameter can be specified as an array or as a \"factored kernel\", a tuple (filt1, filt2, ...) of filters to apply along each axis of the image. In cases where you know your kernel is separable, this format can speed processing. Each of these should have the same dimensionality as the image itself, and be shaped in a manner that indicates the filtering axis, e.g., a 3x1 filter for filtering the first dimension and a 1x3 filter for filtering the second dimension. In two dimensions, any kernel passed as a single matrix is checked for separability; if you want to eliminate that check, pass the kernel as a single-element tuple, (kernel,).\n\nChoices for border\n\nAt the image edge, border is used to specify the padding which will be used to extrapolate the image beyond its original bounds. \n\n\"replicate\" (default)\n\nThe border pixels extend beyond the image boundaries.\n\n   ╭────┏━━━━━━┓────╮\n   │aaaa┃abcdef┃ffff│\n   ╰────┗━━━━━━┛────╯\n\n\"circular\"\n\nThe border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.\n\n\n   ╭────┏━━━━━━┓────╮\n   │cdef┃abcdef┃abcd│\n   ╰────┗━━━━━━┛────╯\n\n\n\"reflect\"\n\nThe border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.\n\n\n   ╭────┏━━━━━━┓────╮\n   │dcba┃abcdef┃fedc│\n   ╰────┗━━━━━━┛────╯\n\n\n\"symmetric\"\n\nThe border pixels reflect relative to the edge itself.\n\n\n   ╭────┏━━━━━━┓────╮\n   │edcb┃abcdef┃edcb│\n   ╰────┗━━━━━━┛────╯\n\n\nFill(m)\n\nThe border pixels are filled with a specified value m.\n\n\n   ╭────┏━━━━━━┓────╮\n   │mmmm┃abcdef┃mmmm│\n   ╰────┗━━━━━━┛────╯\n\n\nInner()\n\nIndicate that edges are to be discarded in filtering, only the interior of the result is to be returned.\n\nNA()\n\nChoose filtering using \"NA\" (Not Available) boundary conditions. This is most appropriate for filters that have only positive weights, such as blurring filters.\n\nSee also: Pad, padarray, Inner, NA  and NoPad\n\nChoices for alg\n\nThe alg parameter allows you to choose the particular algorithm: Algorithm.FIR() (finite impulse response, aka traditional digital filtering) or Algorithm.FFT() (Fourier-based filtering). If no choice is specified, one will be chosen based on the size of the image and kernel in a way that strives to deliver good performance. Alternatively you can use a custom filter type, like KernelFactors.IIRGaussian.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.imfilter!","page":"Function reference","title":"ImageFiltering.imfilter!","text":"imfilter!(imgfilt, img, kernel, [border=\"replicate\"], [alg])\nimfilter!(r, imgfilt, img, kernel, border::Pad)\nimfilter!(r, imgfilt, img, kernel, border::NoPad, [inds=axes(imgfilt)])\n\nFilter an array img with kernel kernel by computing their correlation, storing the result in imgfilt.\n\nThe indices of imgfilt determine the region over which the filtered image is computed–-you can use this fact to select just a specific region of interest, although be aware that the input img might still get padded.  Alteratively, explicitly provide the indices inds of imgfilt that you want to calculate, and use NoPad boundary conditions. In such cases, you are responsible for supplying appropriate padding: img must be indexable for all of the locations needed for calculating the output. This syntax is best-supported for FIR filtering; in particular, that that IIR filtering can lead to results that are inconsistent with respect to filtering the entire array.\n\nSee also: imfilter.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.imgradients","page":"Function reference","title":"ImageFiltering.imgradients","text":"imgradients(img, kernelfun=KernelFactors.ando3, border=\"replicate\") -> gimg1, gimg2, ...\n\nEstimate the gradient of img in the direction of the first and second dimension at all points of the image, using a kernel specified by kernelfun.\n\nReturns a tuple-of-arrays, (gimg1, gimg2, ...), one for each dimension of the input: gimg1 corresponds to the derivative with respect to the first dimension, gimg2 to the second, and so on.\n\nExample\n\nusing Images, ImageFiltering, TestImages\nimg = testimage(\"mandrill\")\nimgr = imgradients(img, KernelFactors.sobel, \"reflect\")\nmosaicview(imgr...)\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.MapWindow.mapwindow","page":"Function reference","title":"ImageFiltering.MapWindow.mapwindow","text":"mapwindow(f::F, img, window; \n    border = \"replicate\",\n    indices = default_imginds(img, window, border), callmode=:copy!)\n\nApply f to sliding windows of img, with window size or axes specified by window. For example,mapwindow(median!, img, window)returns an Array of values similar toimg(median-filtered, of course), whereasmapwindow(extrema, img, window)returns an Array of (min, max) tuples over a window of size window centered on each point ofimg`.\n\nThe function f receives a buffer buf` for the window of data surrounding the current point.\n\nIf window` is specified as a Dims-tuple (tuple-of-integers), then all the integers must be odd and the window is centered around the current image point. \n\nFor example, if window = (3,3), then f will receive an Array bufcorresponding to offsets (-1:1, -1:1) from theimgf[i, j]`for which this is currently being computed. Alternatively, window can be a tuple ofAbstractUnitRanges, in which case the specified ranges are used forbuf`; this allows you to use asymmetric windows if needed.\n\nRestricting to a subimage\n\nThe indices keyword allows you to omit unnecessary computations, if you want to do things like mapwindow on a subimage, or a strided variant of mapwindow.\n\nThis call:\n\nmapwindow(f, img, window, indices=(2:5, 1:2:7))\n\nis more efficient than the equivalent:\n\nmapwindow(f, img, window)[2:5, 1:2:7]\n\nbecause it omits computation of the unused values.\n\nBecause the data in the buffer buf that is received by f is copied from img, and the buffer's memory is reused, f should not return references to buf.\n\nThis code:\n\nf = buf -> copy(buf) # as opposed to f = buf -> buf\nmapwindow(f, img, window, indices=(2:5, 1:2:7))\n\nwould work as expected.\n\nFor functions that can only take AbstractVector inputs, you might have to first specialize default_shape:\n\nf = v -> quantile(v, 0.75)\nImageFiltering.MapWindow.default_shape(::typeof(f)) = vec\n\nand then mapwindow(f, img, (m, n)) should filter at the 75th quantile.\n\nSee also: imfilter.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.MapWindow.mapwindow!","page":"Function reference","title":"ImageFiltering.MapWindow.mapwindow!","text":"mapwindow!(f, out, img, window; border=\"replicate\", indices=axes(img))\n\nVariant of mapwindow, with preallocated output. If out and img have overlapping memory regions, behaviour is undefined.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#Kernel","page":"Function reference","title":"Kernel","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"Kernel\nKernel.ando3\nKernel.ando4\nKernel.ando5\nKernel.bickley\nKernel.DoG\nKernel.gabor\nKernel.gaussian\nKernel.Laplacian\nKernel.LoG\nKernel.moffat\nKernel.prewitt\nKernel.scharr\nKernel.sobel","category":"page"},{"location":"reference/function_reference/#ImageFiltering.Kernel","page":"Function reference","title":"ImageFiltering.Kernel","text":"Kernel is a module implementing filtering (correlation) kernels of full dimensionality. The following kernels are supported:\n\nsobel\nprewitt\nando3, ando4, and ando5\nscharr\nbickley\ngaussian\nDoG (Difference-of-Gaussian)\nLoG (Laplacian-of-Gaussian)\nLaplacian\ngabor\nmoffat\n\nSee also: KernelFactors.\n\n\n\n\n\n","category":"module"},{"location":"reference/function_reference/#ImageFiltering.Kernel.ando3","page":"Function reference","title":"ImageFiltering.Kernel.ando3","text":"    diff1, diff2 = ando3()\n\nReturn 3 times 3 correlation kernels for two-dimensional gradient compution using Ando's \"optimal\" filters. The diff1 kernel computes the gradient along the y-axis (first dimension), and the diff2 kernel computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = ando3(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using Ando's \"optimal\" filters of size 3. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: KernelFactors.ando3, Kernel.ando4, Kernel.ando5 and  ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.ando4","page":"Function reference","title":"ImageFiltering.Kernel.ando4","text":"    diff1, diff2 = ando4()\n\nReturn 4 times 4 correlation  kernels for two-dimensional gradient compution using Ando's \"optimal\" filters.  The diff1 kernel computes the gradient along the y-axis (first dimension), and  the diff2 kernel computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = ando4(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using Ando's \"optimal\" filters of size 4. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: KernelFactors.ando4, Kernel.ando3, Kernel.ando5 and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.ando5","page":"Function reference","title":"ImageFiltering.Kernel.ando5","text":"    diff1, diff2 = ando5()\n\nReturn 5 times 5 correlation  kernels for two-dimensional gradient compution using Ando's \"optimal\" filters.  The diff1 kernel computes the gradient along the y-axis (first dimension), and  the diff2 kernel computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = ando5(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using Ando's \"optimal\" filters of size 5. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: KernelFactors.ando5, Kernel.ando3, Kernel.ando4 and  ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.bickley","page":"Function reference","title":"ImageFiltering.Kernel.bickley","text":"    diff1, diff2 = bickley()\n\nReturn 3 times 3 correlation kernels for two-dimensional gradient compution using the Bickley operator. The diff1 kernel computes the gradient along the y-axis (first dimension), and the diff2 kernel computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = bickley(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using the Bickley operator. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nW. G. Bickley, \"Finite difference formulae for the square lattice,\" The Quarterly Journal of Mechanics and Applied Mathematics, vol. 1, no. 1, pp. 35–42, 1948.  doi:10.1093/qjmam/1.1.35\n\nSee also: KernelFactors.bickley, Kernel.prewitt, Kernel.ando3,  Kernel.scharr and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.DoG","page":"Function reference","title":"ImageFiltering.Kernel.DoG","text":"DoG((σp1, σp2, ...), (σm1, σm2, ...), [l1, l2, ...]) -> k\nDoG((σ1, σ2, ...))                                   -> k\nDoG(σ::Real)                                         -> k\n\nConstruct a multidimensional difference-of-gaussian kernel k, equal to gaussian(σp, l)-gaussian(σm, l).  When only a single σ is supplied, the default is to choose σp = σ, σm = √2 σ. Optionally provide the kernel length l; the default is to extend by two max(σp,σm) in each direction from the center. l must be odd.\n\nIf σ is provided as a single number, a symmetric 2d DoG kernel is returned.\n\nSee also: KernelFactors.IIRGaussian.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.gabor","page":"Function reference","title":"ImageFiltering.Kernel.gabor","text":"gabor(size_x,size_y,σ,θ,λ,γ,ψ) -> (k_real,k_complex)\n\nReturns a 2 Dimensional Complex Gabor kernel contained in a tuple where\n\nsize_x, size_y denote the size of the kernel\nσ denotes the standard deviation of the Gaussian envelope\nθ represents the orientation of the normal to the parallel stripes of a Gabor function\nλ represents the wavelength of the sinusoidal factor\nγ is the spatial aspect ratio, and specifies the ellipticity of the support of the Gabor function\nψ is the phase offset\n\n#Citation N. Petkov and P. Kruizinga, “Computational models of visual neurons specialised in the detection of periodic and aperiodic oriented visual stimuli: bar and grating cells,” Biological Cybernetics, vol. 76, no. 2, pp. 83–96, Feb. 1997. doi.org/10.1007/s004220050323\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.gaussian","page":"Function reference","title":"ImageFiltering.Kernel.gaussian","text":"gaussian((σ1, σ2, ...), [(l1, l2, ...)]) -> g\ngaussian(σ)                  -> g\n\nConstruct a multidimensional gaussian filter, with standard deviation σd along dimension d. Optionally provide the kernel length l, which must be a tuple of the same length.\n\nIf σ is supplied as a single number, a symmetric 2d kernel is constructed.\n\nSee also: KernelFactors.gaussian.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.Laplacian","page":"Function reference","title":"ImageFiltering.Kernel.Laplacian","text":"Laplacian((true,true,false,...))\nLaplacian(dims, N)\nLaplacian()\n\nLaplacian kernel in N dimensions, taking derivatives along the directions marked as true in the supplied tuple. Alternatively, one can pass dims, a listing of the dimensions for differentiation. (However, this variant is not inferrable.)\n\nLaplacian() is the 2d laplacian, equivalent to Laplacian((true,true)).\n\nThe kernel is represented as an opaque type, but you can use convert(AbstractArray, L) to convert it into array format.\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Kernel.LoG","page":"Function reference","title":"ImageFiltering.Kernel.LoG","text":"LoG((σ1, σ2, ...)) -> k\nLoG(σ)             -> k\n\nConstruct a Laplacian-of-Gaussian kernel k. σd is the gaussian width along dimension d.  If σ is supplied as a single number, a symmetric 2d kernel is returned.\n\nSee also: KernelFactors.IIRGaussian and Kernel.Laplacian.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.moffat","page":"Function reference","title":"ImageFiltering.Kernel.moffat","text":"moffat(α, β, ls) -> k\n\nConstructs a 2D, symmetric Moffat kernel k with core width, α, and power, β. Size of kernel defaults to 4 * full-width-half-max or as specified in ls. See this notebook for details.\n\nCitation\n\nMoffat, A. F. J. \"A theoretical investigation of focal stellar images in the photographic emulsion and application to photographic photometry.\" Astronomy and Astrophysics 3 (1969): 455.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.prewitt","page":"Function reference","title":"ImageFiltering.Kernel.prewitt","text":"    diff1, diff2 = prewitt()\n\nReturn 3 times 3 correlation kernels for two-dimensional gradient compution using the Prewitt operator. The diff1 kernel computes the gradient along the y-axis (first dimension), and the diff2 kernel computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = prewitt(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using the Prewitt operator. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nJ. M. Prewitt, \"Object enhancement and extraction,\" Picture processing and Psychopictorics, vol. 10, no. 1, pp. 15–19, 1970.\n\nSee also: KernelFactors.prewitt, Kernel.sobel, Kernel.ando3, Kernel.scharr,Kernel.bickley and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.scharr","page":"Function reference","title":"ImageFiltering.Kernel.scharr","text":"    diff1, diff2 = scharr()\n\nReturn 3 times 3 correlation kernels for two-dimensional gradient compution using the Scharr operator. The diff1 kernel computes the gradient along the y-axis (first dimension), and the diff2 kernel  computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = scharr(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using the Scharr operator. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nH. Scharr and  J. Weickert, \"An anisotropic diffusion algorithm with optimized rotation invariance,\" Mustererkennung 2000, pp. 460–467, 2000. doi:10.1007/978-3-642-59802-9_58\n\nSee also: KernelFactors.scharr, Kernel.prewitt, Kernel.ando3, Kernel.bickley and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.sobel","page":"Function reference","title":"ImageFiltering.Kernel.sobel","text":"    diff1, diff2 = sobel()\n\nReturn 3 times 3 correlation kernels for two-dimensional gradient compution using the Sobel operator. The diff1 kernel computes the gradient along the y-axis (first dimension), and the diff2 kernel computes the gradient along the x-axis (second dimension). diff1 == rotr90(diff2)\n\n    (diff,) = sobel(extended::NTuple{N,Bool}, d)\n\nReturn (a tuple of) the N-dimensional correlation kernel for gradient compution along the dimension d using the Sobel operator. If extended[dim] is false, diff will have size 1 along that dimension.\n\nCitation\n\nP.-E. Danielsson and O. Seger, \"Generalized and separable sobel operators,\" in  Machine Vision for Three-Dimensional Scenes,  H. Freeman, Ed.  Academic Press, 1990,  pp. 347–379. doi:10.1016/b978-0-12-266722-0.50016-6\n\nSee also: KernelFactors.sobel, Kernel.prewitt, Kernel.ando3, Kernel.scharr, Kernel.bickley and imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#KernelFactors","page":"Function reference","title":"KernelFactors","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"KernelFactors\nKernelFactors.ando3\nKernelFactors.ando4\nKernelFactors.ando5\nKernelFactors.bickley\nKernelFactors.gaussian\nKernelFactors.IIRGaussian\nKernelFactors.prewitt\nKernelFactors.scharr\nKernelFactors.sobel\nKernelFactors.TriggsSdika","category":"page"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors","page":"Function reference","title":"ImageFiltering.KernelFactors","text":"KernelFactors is a module implementing separable filtering kernels, each stored in terms of their factors. The following kernels are supported:\n\nbox\nsobel\nprewitt\nando3, ando4, and ando5 (the latter in 2d only)\nscharr\nbickley\ngaussian\nIIRGaussian (approximate gaussian filtering, fast even for large σ)\n\nSee also: Kernel.\n\n\n\n\n\n","category":"module"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.ando3","page":"Function reference","title":"ImageFiltering.KernelFactors.ando3","text":"    kern1, kern2 = ando3()\n\nReturn a factored form of Ando's \"optimal\" 3 times 3 gradient filters for dimensions 1 and 2 of your image.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: Kernel.ando3,KernelFactors.ando4, KernelFactors.ando5 and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = ando3(extended::NTuple{N,Bool}, d)\n\nReturn a factored Ando filter (size 3) for computing the gradient in N dimensions along axis d.  If extended[dim] is false, kern will have size 1 along that dimension.\n\nSee also: KernelFactors.ando4, KernelFactors.ando5 and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.ando4","page":"Function reference","title":"ImageFiltering.KernelFactors.ando4","text":"    kern1, kern2 = ando4()\n\nReturn separable approximations of Ando's \"optimal\" 4x4 filters for dimensions 1 and 2 of your image.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: Kernel.ando4 and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = ando4(extended::NTuple{N,Bool}, d)\n\nReturn a factored Ando filter (size 4) for computing the gradient in N dimensions along axis d.  If extended[dim] is false, kern will have size 1 along that dimension.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: Kernel.ando4 and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.ando5","page":"Function reference","title":"ImageFiltering.KernelFactors.ando5","text":"    kern1, kern2 = ando5()\n\nReturn a separable approximations of Ando's \"optimal\" 5x5 gradient filters for dimensions 1 and 2 of your image.\n\nCitation\n\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\n\nSee also: Kernel.ando5 and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = ando5(extended::NTuple{N,Bool}, d)\n\nReturn a factored Ando filter (size 5) for computing the gradient in N dimensions along axis d.  If extended[dim] is false, kern will have size 1 along that dimension.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.bickley","page":"Function reference","title":"ImageFiltering.KernelFactors.bickley","text":"    kern1, kern2 = bickley()\n\nReturn factored Bickley filters for dimensions 1 and 2 of your image.  Each is a 2-tuple of one-dimensional filters.\n\nCitation\n\nW. G. Bickley, \"Finite difference formulae for the square lattice,\" The Quarterly Journal of Mechanics and Applied Mathematics, vol. 1, no. 1, pp. 35–42, 1948.  doi:10.1093/qjmam/1.1.35\n\nSee also: Kernel.bickley and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = bickley(extended::NTuple{N,Bool}, d)\n\nReturn a factored Bickley filter for computing the gradient in N dimensions along axis d. If extended[dim] is false, kern will have size 1 along that dimension.\n\nSee also: Kernel.bickley and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.gaussian","page":"Function reference","title":"ImageFiltering.KernelFactors.gaussian","text":"gaussian(σ::Real, [l]) -> g\n\nConstruct a 1d gaussian kernel g with standard deviation σ, optionally providing the kernel length l. The default is to extend by two σ in each direction from the center. l must be odd.\n\n\n\n\n\ngaussian((σ1, σ2, ...), [l]) -> (g1, g2, ...)\n\nConstruct a multidimensional gaussian filter as a product of single-dimension factors, with standard deviation σd along dimension d. Optionally provide the kernel length l, which must be a tuple of the same length.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.IIRGaussian","page":"Function reference","title":"ImageFiltering.KernelFactors.IIRGaussian","text":"IIRGaussian([T], σ; emit_warning::Bool=true)\n\nConstruct an infinite impulse response (IIR) approximation to a Gaussian of standard deviation σ. σ may either be a single real number or a tuple of numbers; in the latter case, a tuple of such filters will be created, each for filtering a different dimension of an array.\n\nOptionally specify the type T for the filter coefficients; if not supplied, it will match σ (unless σ is not floating-point, in which case Float64 will be chosen).\n\nCitation\n\nI. T. Young, L. J. van Vliet, and M. van Ginkel, \"Recursive Gabor Filtering\". IEEE Trans. Sig. Proc., 50: 2798-2805 (2002).\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.prewitt","page":"Function reference","title":"ImageFiltering.KernelFactors.prewitt","text":"    kern1, kern2 = prewitt()\n\nReturn factored Prewitt filters for dimensions 1 and 2 of your image. Each is a 2-tuple of one-dimensional filters.\n\nCitation\n\nJ. M. Prewitt, \"Object enhancement and extraction,\" Picture processing and Psychopictorics, vol. 10, no. 1, pp. 15–19, 1970.\n\nSee also: Kernel.prewitt and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = prewitt(extended::NTuple{N,Bool}, d)\n\nReturn a factored Prewitt filter for computing the gradient in N dimensions along axis d. If extended[dim] is false, kern will have size 1 along that dimension.\n\nSee also: Kernel.prewitt and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.scharr","page":"Function reference","title":"ImageFiltering.KernelFactors.scharr","text":"    kern1, kern2 = scharr()\n\nReturn factored Scharr filters for dimensions 1 and 2 of your image.  Each is a 2-tuple of one-dimensional filters.\n\nCitation\n\nH. Scharr and  J. Weickert, \"An anisotropic diffusion algorithm with optimized rotation invariance,\" Mustererkennung 2000, pp. 460–467, 2000. doi:10.1007/978-3-642-59802-9_58\n\nSee also: Kernel.scharr and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = scharr(extended::NTuple{N,Bool}, d)\n\nReturn a factored Scharr filter for computing the gradient in N dimensions along axis d. If extended[dim] is false, kern will have size 1 along that dimension.\n\nSee also: Kernel.scharr and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.sobel","page":"Function reference","title":"ImageFiltering.KernelFactors.sobel","text":"    kern1, kern2 = sobel()\n\nReturn factored  Sobel filters for dimensions 1 and 2 of a two-dimensional image. Each is a 2-tuple of one-dimensional filters.\n\nCitation\n\nP.-E. Danielsson and O. Seger, \"Generalized and separable sobel operators,\" in  Machine Vision for Three-Dimensional Scenes,  H. Freeman, Ed.  Academic Press, 1990,  pp. 347–379. doi:10.1016/b978-0-12-266722-0.50016-6\n\nSee also: Kernel.sobel  and ImageFiltering.imgradients.\n\n\n\n\n\n    kern = sobel(extended::NTuple{N,Bool}, d)\n\nReturn a factored Sobel filter for computing the gradient in N dimensions along axis d. If extended[dim] is false, kern will have size 1 along that dimension.\n\nSee also: Kernel.sobel and ImageFiltering.imgradients.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.TriggsSdika","page":"Function reference","title":"ImageFiltering.KernelFactors.TriggsSdika","text":"TriggsSdika(a, b, scale, M)\n\nDefines a kernel for one-dimensional infinite impulse response (IIR) filtering. a is a \"forward\" filter, b a \"backward\" filter, M is a matrix for matching boundary conditions at the right edge, and scale is a constant scaling applied to each element at the conclusion of filtering.\n\nCitation\n\nB. Triggs and M. Sdika, \"Boundary conditions for Young-van Vliet recursive filtering\". IEEE Trans. on Sig. Proc. 54: 2365-2367 (2006).\n\n\n\n\n\nTriggsSdika(ab, scale)\n\nCreate a symmetric Triggs-Sdika filter (with a = b = ab). M is calculated for you. Only length 3 filters are currently supported.\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#Kernel-utilities","page":"Function reference","title":"Kernel utilities","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"OffsetArrays.center\nOffsetArrays.centered\nkernelfactors\nreflect","category":"page"},{"location":"reference/function_reference/#OffsetArrays.center","page":"Function reference","title":"OffsetArrays.center","text":"center(A, [r::RoundingMode=RoundDown])::Dims\n\nReturn the center coordinate of given array A. If size(A, k) is even, a rounding procedure will be applied with mode r.\n\ncompat: OffsetArrays 1.9\nThis method requires at least OffsetArrays 1.9.\n\nExamples\n\njulia> A = reshape(collect(1:9), 3, 3)\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\njulia> c = OffsetArrays.center(A)\n(2, 2)\n\njulia> A[c...]\n5\n\njulia> Ao = OffsetArray(A, -2, -2); # axes (-1:1, -1:1)\n\njulia> c = OffsetArrays.center(Ao)\n(0, 0)\n\njulia> Ao[c...]\n5\n\nTo shift the center coordinate of the given array to (0, 0, ...), you can use centered.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#OffsetArrays.centered","page":"Function reference","title":"OffsetArrays.centered","text":"centered(A, cp=center(A)) -> Ao\n\nShift the center coordinate/point cp of array A to (0, 0, ..., 0). Internally, this is equivalent to OffsetArray(A, .-cp).\n\ncompat: OffsetArrays 1.9\nThis method requires at least OffsetArrays 1.9.\n\nExamples\n\njulia> A = reshape(collect(1:9), 3, 3)\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\njulia> Ao = OffsetArrays.centered(A); # axes (-1:1, -1:1)\n\njulia> Ao[0, 0]\n5\n\njulia> Ao = OffsetArray(A, OffsetArrays.Origin(0)); # axes (0:2, 0:2)\n\njulia> Aoo = OffsetArrays.centered(Ao); # axes (-1:1, -1:1)\n\njulia> Aoo[0, 0]\n5\n\nUsers are allowed to pass cp to change how \"center point\" is interpreted, but the meaning of the output array should be reinterpreted as well. For instance, if cp = map(last, axes(A)) then this function no longer shifts the center point but instead the bottom-right point to (0, 0, ..., 0). A commonly usage of cp is to change the rounding behavior when the array is of even size at some dimension:\n\njulia> A = reshape(collect(1:4), 2, 2) # Ideally the center should be (1.5, 1.5) but OffsetArrays only support integer offsets\n2×2 Matrix{Int64}:\n 1  3\n 2  4\n\njulia> OffsetArrays.centered(A, OffsetArrays.center(A, RoundUp)) # set (2, 2) as the center point\n2×2 OffsetArray(::Matrix{Int64}, -1:0, -1:0) with eltype Int64 with indices -1:0×-1:0:\n 1  3\n 2  4\n\njulia> OffsetArrays.centered(A, OffsetArrays.center(A, RoundDown)) # set (1, 1) as the center point\n2×2 OffsetArray(::Matrix{Int64}, 0:1, 0:1) with eltype Int64 with indices 0:1×0:1:\n 1  3\n 2  4\n\nSee also center.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.kernelfactors","page":"Function reference","title":"ImageFiltering.KernelFactors.kernelfactors","text":"kernelfactors(factors::Tuple)\n\nPrepare a factored kernel for filtering. If passed a 2-tuple of vectors of lengths m and n, this will return a 2-tuple of ReshapedVectors that are effectively of sizes m×1 and 1×n. In general, each successive factor will be reshaped to extend along the corresponding dimension.\n\nIf passed a tuple of general arrays, it is assumed that each is shaped appropriately along its \"leading\" dimensions; the dimensionality of each is \"extended\" to N = length(factors), appending 1s to the size as needed.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.Kernel.reflect","page":"Function reference","title":"ImageFiltering.Kernel.reflect","text":"reflect(kernel) --> reflectedkernel\n\nCompute the pointwise reflection around 0, 0, ... of the kernel kernel.  Using imfilter with a reflectedkernel performs convolution, rather than correlation, with respect to the original kernel.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#Boundaries-and-padding","page":"Function reference","title":"Boundaries and padding","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"BorderArray\nFill\nInner\nNA\nNoPad\nPad\npadarray","category":"page"},{"location":"reference/function_reference/#ImageFiltering.BorderArray","page":"Function reference","title":"ImageFiltering.BorderArray","text":"BorderArray(inner::AbstractArray, border::AbstractBorder) <: AbstractArray\n\nConstruct a thin wrapper around the array inner, with given border. No data is copied in the constructor, instead border values are computed on the fly in getindex calls. Useful for stencil computations. See also padarray.\n\nExamples\n\njulia> using ImageFiltering\n\njulia> arr = reshape(1:6, (2,3))\n2×3 reshape(::UnitRange{Int64}, 2, 3) with eltype Int64:\n 1  3  5\n 2  4  6\n\njulia> BorderArray(arr, Pad((1,1)))\nBorderArray{Int64,2,Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}},Pad{2}} with indices 0:3×0:4:\n 1  1  3  5  5\n 1  1  3  5  5\n 2  2  4  6  6\n 2  2  4  6  6\n\njulia> BorderArray(arr, Fill(10, (2,1)))\nBorderArray{Int64,2,Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}},Fill{Int64,2}} with indices -1:4×0:4:\n 10  10  10  10  10\n 10  10  10  10  10\n 10   1   3   5  10\n 10   2   4   6  10\n 10  10  10  10  10\n 10  10  10  10  10\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Fill","page":"Function reference","title":"ImageFiltering.Fill","text":"struct Fill{T,N} <: AbstractBorder\n    value::T\n    lo::Dims{N}\n    hi::Dims{N}\nend\n\nFill is a type that designates a particular value which will be used to extrapolate pixels beyond the boundary of an image.\n\nOutput\n\nThe type Fill specifying the value with which the boundary of the image should be padded.\n\nDetails\n\nWhen representing a two-dimensional spatial image filtering operation as a discrete convolution between an image and a D times D filter, the results are undefined for pixels closer than D pixels from the border of the image. To define the operation near and at the border, you need a scheme for extrapolating pixels beyond the edge. The Fill type allows you to specify a particular value which will be used in the extrapolation. For more elaborate extrapolation schemes, see Pad.\n\nThe type facilitates the padding of one, two, or multi-dimensional images.\n\nYou can specify a different amount of padding at the lower and upper borders of each dimension of the image (top, left, bottom, and right in two dimensions).\n\nExample\n\nTo illustrate this, consider an image consisting of a row of six pixels which are specified alphabetically:\n\n    ┏━━━━━━┓ \n    ┃abcdef┃ \n    ┗━━━━━━┛ \n\nPadding with a constant value m only on the left and right border looks like this:\n\n╭────┏━━━━━━┓────╮\n│mmmm┃abcdef┃mmmm│\n╰────┗━━━━━━┛────╯\n\n(Analogous consequences hold for the top and bottom border.)\n\nSee also: Pad, padarray, Inner and NoPad\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Inner","page":"Function reference","title":"ImageFiltering.Inner","text":"Inner()\nInner(lo, hi)\n\nIndicate that edges are to be discarded in filtering, only the interior of the result is to be returned.\n\nExample:\n\nimfilter(img, kernel, Inner())\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.NA","page":"Function reference","title":"ImageFiltering.NA","text":"NA(na=isnan)\n\nChoose filtering using \"NA\" (Not Available) boundary conditions. This is most appropriate for filters that have only positive weights, such as blurring filters. Effectively, the output value is normalized in the following way:\n\n          filtered array with Fill(0) boundary conditions\noutput =  -----------------------------------------------\n          filtered 1     with Fill(0) boundary conditions\n\nArray elements for which na returns true are also considered outside array boundaries.\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.NoPad","page":"Function reference","title":"ImageFiltering.NoPad","text":"NoPad()\nNoPad(border)\n\nIndicates that no padding should be applied to the input array, or that you have already pre-padded the input image. Passing a border object allows you to preserve \"memory\" of a border choice; it can be retrieved by indexing with [].\n\nExample\n\nThe commands\n\nnp = NoPad(Pad(:replicate))\nimfilter!(out, img, kernel, np)\n\nrun filtering directly, skipping any padding steps.  Every entry of out must be computable using in-bounds operations on img and kernel.\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Pad","page":"Function reference","title":"ImageFiltering.Pad","text":"    struct Pad{N} <: AbstractBorder\n        style::Symbol\n        lo::Dims{N}    # number to extend by on the lower edge for each dimension\n        hi::Dims{N}    # number to extend by on the upper edge for each dimension\n    end\n\nPad is a type that designates the form of padding which should be used to extrapolate pixels beyond the boundary of an image. Instances must set style, a Symbol specifying the boundary conditions of the image.\n\nOutput\n\nThe type Pad specifying how the boundary of an image should be padded.\n\nExtended help\n\nWhen representing a spatial two-dimensional image filtering operation as a discrete convolution between the image and a D times D filter, the results are undefined for pixels closer than D pixels from the border of the image. To define the operation near and at the border, one needs a scheme for extrapolating pixels beyond the edge. The Pad type allows one to specify the necessary extrapolation scheme.\n\nThe type facilitates the padding of one, two or multi-dimensional images.\n\nYou can specify a different amount of padding at the lower and upper borders of each dimension of the image (top, left, bottom and right in two dimensions).\n\nOptions\n\nSome valid style options are described below. As an indicative example of each option the results of the padding are illustrated on an image consisting of a row of six pixels which are specified alphabetically:\n\n        ┏━━━━━━┓ \n        ┃abcdef┃ \n        ┗━━━━━━┛ \n\nWe show the effects of padding only on the left and right border, but analogous consequences hold for the top and bottom border.\n\n:replicate (Default)\n\nThe border pixels extend beyond the image boundaries.\n\n   ╭────┏━━━━━━┓────╮\n   │aaaa┃abcdef┃ffff│\n   ╰────┗━━━━━━┛────╯\n\nSee also: Fill, padarray, Inner and NoPad\n\n:circular\n\nThe border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.\n\n\n   ╭────┏━━━━━━┓────╮\n   │cdef┃abcdef┃abcd│\n   ╰────┗━━━━━━┛────╯\n\n\nSee also: Fill, padarray, Inner and NoPad\n\n:symmetric\n\nThe border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.\n\n\n   ╭────┏━━━━━━┓────╮\n   │edcb┃abcdef┃edcb│\n   ╰────┗━━━━━━┛────╯\n\n\n:reflect\n\nThe border pixels reflect relative to the edge itself.\n\n\n   ╭────┏━━━━━━┓────╮\n   │dcba┃abcdef┃fedc│\n   ╰────┗━━━━━━┛────╯\n\n\nSee also: Fill,padarray, Inner and NoPad.\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.padarray","page":"Function reference","title":"ImageFiltering.padarray","text":"padarray([T], img, border)\n\nGenerate a padded image from an array img and a specification border of the boundary conditions and amount of padding to add.\n\nReturn a padded image. The function supports one, two or multi-dimensional images. You can specify the element type T of the output image.\n\nSee Pad and Fill for details.\n\nExamples\n\nPadding\n\nThe main syntax for Pad is (style, m, n, ...) or (style, (m, n)), where m pixels are added to dimension 1 (top and bottom), n pixels for dimension 2, and so forth.\n\nAdd 30 to left and right, 40 to top and bottom:\n\npadarray(A, Pad(:replicate, 30, 40))\npadarray(A, Pad(:circular, 30, 40))\npadarray(A, Pad(:symmetric, 30, 40))\npadarray(A, Pad(:reflect, 30, 40))\n\nAdd 30 above, 40 to left, 50 to bottom, 60 to right:\n\npadarray(A, Pad(0, (30, 40), (50, 60)))\npadarray(A, Pad(0, (30, 40), (50, 60)))\n\n3D\n\npadarray(A, Pad(:replicate, 1, 1, 1)) \npadarray(A, Fill(0, (1, 1, 1))) \n\nFilling\n\nThe main syntax for Fill is (value, m, n) or (value, (m, n)) where the image is prepended by m pixels and appended by n pixels in each dimension.\n\nAdd 20 -1 values above, 30 to left, 40 to bottom, 50 to right:\n\npadarray(A, Fill(-1, (20, 30), (40, 50))) \n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#Find-local-extrema","page":"Function reference","title":"Find local extrema","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"findlocalmaxima\nfindlocalminima","category":"page"},{"location":"reference/function_reference/#ImageFiltering.findlocalmaxima","page":"Function reference","title":"ImageFiltering.findlocalmaxima","text":"findlocalmaxima(img; window=default_window(img), edges=true) -> Vector{CartesianIndex}\n\nReturns the coordinates of elements whose value is larger than all of their immediate neighbors. edges is a Boolean specifying whether to include the first and last elements of each dimension, or a tuple-of-Bool specifying edge behavior for each dimension separately.\n\nThe default_window is 3 for each spatial dimension of img, and 1 otherwise, implying that maxima are detected over nearest-neighbors in each spatial \"slice\" by default.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#ImageFiltering.findlocalminima","page":"Function reference","title":"ImageFiltering.findlocalminima","text":"findlocalminima(img; window=default_window(img), edges=true) -> Vector{CartesianIndex}\n\nLike findlocalmaxima, but returns the coordinates of the smallest elements.\n\n\n\n\n\n","category":"function"},{"location":"reference/function_reference/#Algorithms","page":"Function reference","title":"Algorithms","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"Algorithm.FIR\nAlgorithm.FFT\nAlgorithm.IIR\nAlgorithm.Mixed","category":"page"},{"location":"reference/function_reference/#ImageFiltering.Algorithm.FIR","page":"Function reference","title":"ImageFiltering.Algorithm.FIR","text":"Filter using a direct algorithm\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Algorithm.FFT","page":"Function reference","title":"ImageFiltering.Algorithm.FFT","text":"Filter using the Fast Fourier Transform\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Algorithm.IIR","page":"Function reference","title":"ImageFiltering.Algorithm.IIR","text":"Filter with an Infinite Impulse Response filter\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#ImageFiltering.Algorithm.Mixed","page":"Function reference","title":"ImageFiltering.Algorithm.Mixed","text":"Filter with a cascade of mixed types (IIR, FIR)\n\n\n\n\n\n","category":"type"},{"location":"reference/function_reference/#Solvers-for-predefined-models","page":"Function reference","title":"Solvers for predefined models","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"Modules = [ImageFiltering.Models]","category":"page"},{"location":"reference/function_reference/#ImageFiltering.Models","page":"Function reference","title":"ImageFiltering.Models","text":"This submodule provides predefined image-related models and its solvers that can be reused by many image processing tasks.\n\nsolve the Rudin Osher Fatemi (ROF) model using the primal-dual method: solve_ROF_PD and solve_ROF_PD!\n\n\n\n\n\n","category":"module"},{"location":"reference/function_reference/#ImageFiltering.Models.solve_ROF_PD!-Union{Tuple{T}, Tuple{AbstractArray{T}, Tuple, AbstractArray, Real, Integer}} where T","page":"Function reference","title":"ImageFiltering.Models.solve_ROF_PD!","text":"solve_ROF_PD!(out, buffer, img, λ, num_iters)\n\nThe in-place version of solve_ROF_PD.\n\nIt is not uncommon to use ROF solver in a higher-level loop, in which case it makes sense to preallocate the output and intermediate arrays to make it faster.\n\nnote: Buffer\nThe content and meaning of buffer might change without any notice if the internal implementation is changed. Use preallocate_solve_ROF_PD helper function to avoid potential changes.\n\nExamples\n\nusing ImageFiltering.Models: preallocate_solve_ROF_PD\n\nout = similar(img)\nbuffer = preallocate_solve_ROF_PD(img)\nsolve_ROF_PD!(out, buffer, img, 0.2, 30)\n\n\n\n\n\n","category":"method"},{"location":"reference/function_reference/#ImageFiltering.Models.solve_ROF_PD-Union{Tuple{T}, Tuple{AbstractArray{T}, Vararg{Any}}} where T","page":"Function reference","title":"ImageFiltering.Models.solve_ROF_PD","text":"solve_ROF_PD([T], img::AbstractArray, λ; kwargs...)\n\nReturn a smoothed version of img, using Rudin-Osher-Fatemi (ROF) filtering, more commonly known as Total Variation (TV) denoising or TV regularization. This algorithm is based on the primal-dual method.\n\nThis function applies to generic N-dimensional colorant array and is also CUDA-compatible. See also solve_ROF_PD! for the in-place version.\n\nArguments\n\nT: the output element type. By default it is float32(eltype(img)).\nimg: the input image, usually a noisy image.\nλ: the regularization coefficient. Larger λ results in more smoothing.\n\nParameters\n\nnum_iters::Int: The number of iterations before stopping.\n\nExamples\n\nusing ImageFiltering\nusing ImageFiltering.Models: solve_ROF_PD\nusing ImageQualityIndexes\nusing TestImages\n\nimg_ori = float.(testimage(\"cameraman\"))\nimg_noisy = img_ori .+ 0.1 .* randn(size(img_ori))\nassess_psnr(img_noisy, img_ori) # ~20 dB\n\nimg_smoothed = solve_ROF_PD(img_noisy, 0.015, 50)\nassess_psnr(img_smoothed, img_ori) # ~27 dB\n\n# larger λ produces over-smoothed result\nimg_smoothed = solve_ROF_PD(img_noisy, 5, 50)\nassess_psnr(img_smoothed, img_ori) # ~21 dB\n\nExtended help\n\nMathematically, this function solves the following ROF model using the primal-dual method:\n\nmin_u lVert u - g rVert^2 + lambdalvertnabla urvert\n\nReferences\n\n[1] Chambolle, A. (2004). \"An algorithm for total variation minimization and applications\". Journal of Mathematical Imaging and Vision. 20: 89–97\n[2] Wikipedia: Total Variation Denoising\n\n\n\n\n\n","category":"method"},{"location":"reference/function_reference/#Internal-machinery","page":"Function reference","title":"Internal machinery","text":"","category":"section"},{"location":"reference/function_reference/","page":"Function reference","title":"Function reference","text":"KernelFactors.ReshapedOneD","category":"page"},{"location":"reference/function_reference/#ImageFiltering.KernelFactors.ReshapedOneD","page":"Function reference","title":"ImageFiltering.KernelFactors.ReshapedOneD","text":"ReshapedOneD{N,Npre}(data)\n\nReturn an object of dimensionality N, where data must have dimensionality 1. The axes are 0:0 for the first Npre dimensions, have the axes of data for dimension Npre+1, and are 0:0 for the remaining dimensions.\n\ndata must support eltype and ndims, but does not have to be an AbstractArray.\n\nReshapedOneDs allow one to specify a \"filtering dimension\" for a 1-dimensional filter.\n\n\n\n\n\n","category":"type"},{"location":"mapwindows/#Map-windows","page":"Map window","title":"Map windows","text":"","category":"section"},{"location":"mapwindows/#The-mapwindow-function","page":"Map window","title":"The mapwindow function","text":"","category":"section"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"This function allows you to apply a function f to sliding windows of img, with window size or axes specified by window. ","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"mapwindow(f, img, window; [border=\"replicate\"], [indices=axes(img)]) -> imgf","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"For example, mapwindow(median!, img, window) returns an Array of values similar to img (median-filtered, of course), whereas mapwindow(extrema, img, window) returns an Array of (min,max) tuples over a window of size window centered on each point of img.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"The function f receives a buffer buf for the window of data surrounding the current point. If window is specified as a Dims-tuple (tuple-of-integers), then all the integers must be odd and the window is centered around the current image point. For example, if window=(3,3), then f will receive an Array buf corresponding to offsets (-1:1, -1:1) from the imgf[i,j] for which this is currently being computed. Alternatively, window can be a tuple of AbstractUnitRanges, in which case the specified ranges are used for buf; this allows you to use asymmetric windows if needed.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"border specifies how the edges of img should be handled; see imfilter for details.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"Finally indices allows to omit unnecessary computations, if you want to do things like mapwindow on a subimage, or a strided variant of mapwindow. It works as follows:","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"mapwindow(f, img, window, indices=(2:5, 1:2:7)) == mapwindow(f,img,window)[2:5, 1:2:7]","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"although more efficiently because it omits the computation of unused values.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"Because the data in the buffer buf that is received by f is copied from img, and the buffer's memory is reused, f should not return references to buf. ","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"This code:","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"f = buf -> copy(buf) # as opposed to f = buf -> buf\nmapwindow(f, img, window, indices=(2:5, 1:2:7))","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"would work as expected.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"For functions that can only take AbstractVector inputs, you might have to first specialize default_shape:","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"f = v->quantile(v, 0.75)\nImageFiltering.MapWindow.default_shape(::typeof(f)) = vec","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"and then mapwindow(f, img, (m,n)) should filter at the 75th quantile.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"See also: imfilter.","category":"page"},{"location":"mapwindows/#The-mapwindow!()-function","page":"Map window","title":"The mapwindow!() function","text":"","category":"section"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"The mapwindow!() function is a variant of mapwindow, with preallocated output.","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"mapwindow!(f, out, img, window; border=\"replicate\", indices=axes(img))","category":"page"},{"location":"mapwindows/","page":"Map window","title":"Map window","text":"If out and img have overlapping memory regions, the behaviour is undefined.","category":"page"},{"location":"demos/search/template_matching/#Template-Matching","page":"Template Matching","title":"Template Matching","text":"","category":"section"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"(Image: Source code) (Image: Author) (Image: Update time)","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"This demo shows how to find objects in an image using template matching.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"The main idea is to check the similarity between a search target(template) and a subsection of the image. The subsection is usually the same size as the template. Therefore by using mapwindow we can assign a value for every subsection of the image.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"At first we import the following packages.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"using ImageCore: Gray\nusing ImageMorphology: label_components, component_centroids\nusing ImageFiltering: mapwindow, Fill, imfilter, KernelFactors\nusing ImageDistances: sqeuclidean\nusing ImageContrastAdjustment: adjust_histogram, LinearStretching\nusing TestImages\nusing Plots: scatter!, plot","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"ImageCore enables the generation of images, ImageFiltering provides the mapwindow function and ImageFeatures provides functions to label segments of an image. To calculate the similarity squeclidean is used. This defines a distance between two images as:","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"textrmdistance = sum_i^textrmnumber of pixels (textrmtemplate_i - textrmsubsection_i)^2","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"ImageContrastAdjustment provides functions to adjust the histogram, which is useful when an image contains values bigger than 1 or smaller than 0.  The Testimages package will provide our image and plot is used to overlay a scatter plot onto the image.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"To start we first load our image.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"img = testimage(\"moonsurface\")","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"Let's say we want to find the medium sized craters in the image based one of the impact areas. For this we generate a template from a subsection of the image and apply a small gaussian blur using imfilter. The gaussian blur often helps when the search targets are not exactly the same.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"template = img[12:22,20:30]\ntemplate = imfilter(template,KernelFactors.gaussian((0.5,0.5)))","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"Now that we have an image and a template, the next step is to define how we measure the similarity between a section of the image and the template. This can be done in multiple way, but a sum of square distances should work quite well. The ImageDistance package provides an already optimized version called sqeuclidean, which can be used to define a function for mapwindow.  Let's call it SDIFF.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"function SDIFF(template)\n  (subsection)->sqeuclidean(subsection, template)\nend","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"To actually generate our similarity map we use mapwindow in the following way.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"res = mapwindow(SDIFF(template), img, size(template), border=Fill(1)) .|> Gray\nrescaled_map = adjust_histogram(res, LinearStretching())","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"If the subsection is located at the border of the image the image has to be extended and in our case we will fill all values outside the image with 1. One thing to keep in mind is that because all of the square differences will be summed up per subsection the resulting sum can be bigger than 1. This will be a problem if we just convert it to an image to check the values. To rescale the values to be between 0 and 1 we can use adjust_histogram.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"To find the best locations we have to look for small values on the similarity map. This can be done by comparing if the pixel is below a certain value. Let's chose a value of 0.05.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"threshold = rescaled_map .< 0.05\nGray.(threshold)","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"Now we see small blobs at the locations which match our template and we can label the connected regions by label_components.  This will enumerate are connected regions and component_centroids can be used to get the centroid of each region.  component_centroids also return the centroid for the background region, which is at the first position and we will omit it.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"centroids = component_centroids(label_components(threshold))[2:end]","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"To check if it worked correctly we can overlay the centroids with the original image using the Plots package. As the images are stored using the first index for rows we have to reverse the order of the coordinates to match the order of the plotting library.","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"plot(Gray.(img), size=(512,512))\nscatter!(reverse.(centroids), label=\"centroids\", ms=10, alpha=0.5, c=:red, msw=3)","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"","category":"page"},{"location":"demos/search/template_matching/","page":"Template Matching","title":"Template Matching","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"reference/technical/#Technical-background","page":"Technical overview","title":"Technical background","text":"","category":"section"},{"location":"reference/technical/#Introduction","page":"Technical overview","title":"Introduction","text":"","category":"section"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"An image filter can be represented by a function","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":" w sin mathbbZ mid -k_1 le s le k_1   times  t in mathbbZ mid -k_2 le t le k_2     rightarrow mathbbR","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"where k_i  in mathbbN (i = 1,2). It is common to define k_1 = 2a+1 and k_2 = 2b + 1, where a and b are integers, which ensures that the filter dimensions are of odd size. Typically, k_1 equals k_2 and so, dropping the subscripts, one speaks of a k times k filter. Since the domain of the filter represents a grid of spatial coordinates, the filter is often called a mask and is visualized as a grid. ","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"For example, a 3 times 3 mask can be portrayed as follows:","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"scriptsize\nbeginmatrix\nboxed\nbeginmatrix\nphantomw(-9-9) \nw(-1-1) \nphantomw(-9-9) \nendmatrix\n\n\n\n\nboxed\nbeginmatrix\nphantomw(-9-9) \nw(-10) \nphantomw(-9-9) \nendmatrix\n\n \nboxed\nbeginmatrix\nphantomw(-9-9) \nw(-11) \nphantomw(-9-9) \nendmatrix\n\n\n\nboxed\nbeginmatrix\nphantomw(-9-9) \nw(0-1) \nphantomw(-9-9) \nendmatrix\n\n\n\n\nboxed\nbeginmatrix\nphantomw(-9-9) \nw(00) \nphantomw(-9-9) \nendmatrix\n\n \nboxed\nbeginmatrix\nphantomw(-9-9) \nw(01) \nphantomw(-9-9) \nendmatrix\n\n\n\nboxed\nbeginmatrix\nphantomw(-9-9) \nw(1-1) \nphantomw(-9-9) \nendmatrix\n\n\n\n\nboxed\nbeginmatrix\nphantomw(-9-9) \nw(10) \nphantomw(-9-9) \nendmatrix\n\n \nboxed\nbeginmatrix\nphantomw(-9-9) \nw(11) \nphantomw(-9-9) \nendmatrix\n\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"The values of w(st) are referred to as filter coefficients.","category":"page"},{"location":"reference/technical/#Convolution-versus-correlation","page":"Technical overview","title":"Convolution versus correlation","text":"","category":"section"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"There are two fundamental and closely related operations that one regularly performs on an image with a filter. The operations are called discrete correlation and convolution.","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"The correlation operation, denoted by the symbol star,  is given in two dimensions by the expression","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"beginaligned\ng(xy) = w(xy) star f(xy) = sum_s = -a^a sum_t=-b^b w(st) f(x+s y+t)\nendaligned","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"whereas the comparable convolution operation, denoted by the symbol ast, is given in two dimensions by","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"beginaligned\nh(xy) = w(xy) ast f(xy) = sum_s = -a^a sum_t=-b^b w(st) f(x-s y-t)\nendaligned","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"Since a digital image is of finite extent, both of these operations are undefined at the borders of the image. In particular, for an image of size M times N, the function f(x pm s y pm t) is only defined for 1 le x pm s le N and 1 le y pm t le M. In practice one addresses this problem by artificially expanding the domain of the image. For example, one can pad the image with zeros. Other padding strategies are possible, and they are discussed in more detail in the Options section of this documentation.","category":"page"},{"location":"reference/technical/#One-dimensional-illustration","page":"Technical overview","title":"One-dimensional illustration","text":"","category":"section"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"The difference between correlation and convolution is best understood with recourse to a one-dimensional example  adapted from [1]. Suppose that a filter w-101rightarrow mathbbR has coefficients","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"beginmatrix\nboxed1  boxed2  boxed3\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"Consider a discrete unit impulse function f x in mathbbZ mid 1 le x le 7   rightarrow 01  that has been padded with zeros. The function can be visualised as an image","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"boxed\nbeginmatrix\n0  boxed0  boxed0  boxed0  boxed1  boxed0  boxed0  boxed0  0\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"The correlation operation can be interpreted as sliding w along the image and computing the sum of products at each location. For example,","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"beginmatrix\n0  0  0  0  1  0  0  0  0 \n1  2  3         \n 1  2  3         \n  1  2  3        \n   1  2  3       \n    1  2  3      \n     1  2  3    \n      1  2  3\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"yields the output g x in mathbbZ mid 1 le x le 7   rightarrow mathbbR, which when visualized as a digital image, is equal to","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"boxed\nbeginmatrix\nboxed0  boxed0  boxed3  boxed2  boxed1  boxed0  boxed0\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"The interpretation of the convolution operation is analogous to correlation, except that the filter w has been rotated by 180 degrees. In particular,","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"beginmatrix\n0  0  0  0  1  0  0  0  0 \n3  2  1         \n 3  2  1         \n  3  2  1        \n   3  2  1       \n    3  2  1      \n     3  2  1    \n      3  2  1\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"yields the output h x in mathbbZ mid 1 le x le 7   rightarrow mathbbR equal to","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"boxed\nbeginmatrix\nboxed0  boxed0  boxed1  boxed2  boxed3  boxed0  boxed0\nendmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"Instead of rotating the filter mask, one could instead rotate f and still obtained the same convolution result. In fact, the conventional notation for convolution indicates that f is flipped and not w. If w is symmetric, then convolution and correlation give the same outcome.","category":"page"},{"location":"reference/technical/#Two-dimensional-illustration","page":"Technical overview","title":"Two-dimensional illustration","text":"","category":"section"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"For a two-dimensional example, suppose the filter w-1 0 1 times  -101 rightarrow mathbbR  has coefficients","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":" beginmatrix\n boxed1  boxed2  boxed3  \n boxed4  boxed5  boxed6  \n boxed7  boxed8  boxed9\n endmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"and consider a two-dimensional discrete unit impulse function","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":" fx in mathbbZ mid 1 le x le 7   times  y in mathbbZ mid 1 le y le 7  rightarrow  01","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"that has been padded with zeros:","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":" boxed\n beginmatrix\n   0         0          0          0           0          0     0   \n   0  boxed0  boxed0  boxed0   boxed0  boxed0    0   \n   0  boxed0  boxed0  boxed0   boxed0  boxed0    0  \n   0  boxed0  boxed0  boxed1   boxed0  boxed0    0  \n   0  boxed0  boxed0  boxed0   boxed0  boxed0    0  \n   0  boxed0  boxed0  boxed0   boxed0  boxed0    0  \n   0         0          0          0           0          0     0\n endmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"The correlation operation w(xy) star f(xy)  yields the output","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":" boxed\n beginmatrix\n boxed0  boxed0   boxed0  boxed0  boxed0  \n boxed0   boxed9  boxed8  boxed7  boxed0  \n boxed0   boxed6  boxed5  boxed4  boxed0  \n boxed0   boxed3  boxed2  boxed1  boxed0  \n boxed0  boxed0   boxed0  boxed0  boxed0\n endmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"whereas the convolution operation w(xy) ast f(xy) produces","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":" boxed\n beginmatrix\n boxed0  boxed0  boxed0  boxed0  boxed0  \n boxed0  boxed1  boxed2  boxed3  boxed0 \n boxed0  boxed4  boxed5  boxed6  boxed0  \n boxed0  boxed7  boxed8  boxed9  boxed0  \n boxed0  boxed0  boxed0  boxed0  boxed0\n endmatrix","category":"page"},{"location":"reference/technical/#Convolution-and-correlation-as-matrix-multiplication","page":"Technical overview","title":"Convolution and correlation as matrix multiplication","text":"","category":"section"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"Discrete convolution and correlation operations can also be formulated as a matrix multiplication, where one of the inputs is converted to a Toeplitz matrix, and the other is represented as a column vector. For example, consider a function fx in mathbbN mid 1 le x le M  rightarrow mathbbR and a filter w s in mathbbN mid  -k_1 le s le k_1   rightarrow mathbbR. Then the matrix multiplication","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"beginbmatrix\nw(-k_1) \t  0\t     ldots\t 0\t\t    0\t\t\t\nvdots \t w(-k_1) \t ldots\t vdots   0\t        \nw(k_1) \t     vdots    ldots\t 0\t\t    vdots    \n0 \t    \t w(k_1)\t ldots    w(-k_1)   0\t\t    \n0 \t         0\t\t     ldots\t vdots   w(-k_1)\t\nvdots      vdots\t ldots\t w(k_1)    vdots\t\n0            0          0\t\t\t 0\t\t    w(k_1)\nendbmatrix\nbeginbmatrix\nf(1) \nf(2) \nf(3) \nvdots \nf(M)\nendbmatrix","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"is equivalent to the convolution w(s) ast f(x) assuming that the border of f(x) has been padded with zeros.","category":"page"},{"location":"reference/technical/","page":"Technical overview","title":"Technical overview","text":"To represent multidimensional convolution as matrix multiplication one reshapes the multidimensional arrays into column vectors and proceeds in an analogous manner. Naturally, the result of the matrix multiplication will need to be reshaped into an appropriate multidimensional array.","category":"page"},{"location":"padarrays/#Padding-arrays","page":"Padding arrays","title":"Padding arrays","text":"","category":"section"},{"location":"padarrays/#Introduction","page":"Padding arrays","title":"Introduction","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The padarray() function generates a padded image from an array img and a specification border of the boundary conditions and amount of padding to add.","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"padarray([T], img, border)","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The function returns a new image that is an expansion of the input image, in which additional pixels are derived from the border of the input image using the extrapolation scheme specified by border.","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The function supports one, two or multi-dimensional images. You can specify the element type T of the output image.","category":"page"},{"location":"padarrays/#The-Pad-type","page":"Padding arrays","title":"The Pad type","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The type Pad designates the form of padding which should be used to extrapolate pixels beyond the boundary of an image. Instances must set style, a Symbol specifying the boundary conditions of the image.","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The symbol must be one of:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":":replicate (repeat edge values to infinity),\n:circular (image edges \"wrap around\"),\n:symmetric (the image reflects relative to a position between pixels),\n:reflect (the image reflects relative to the edge itself).","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"Refer to the documentation of Pad for more details and examples for each option.","category":"page"},{"location":"padarrays/#The-Fill-type","page":"Padding arrays","title":"The Fill type","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The type Fill designates a particular value which will be used to extrapolate pixels beyond the boundary of an image. ","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"Refer to the documentation of Fill for more details and illustrations.","category":"page"},{"location":"padarrays/#D-Examples","page":"Padding arrays","title":"2D Examples","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The following examples show the effects of modifying the input array:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"mathbfA =\nboxed\nbeginmatrix\n 1   2    3    4  5   6 \n 2   4    6    8  10  12 \n 3   6    9   12  15  18 \n 4   8   12   16  20  24 \n 5   10  15   20  25  30 \n 6   12  18   24  30  36\n endmatrix","category":"page"},{"location":"padarrays/#Examples-with-Pad","page":"Padding arrays","title":"Examples with Pad","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:replicate, 4, 4)) yields","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"boxed\nbeginarrayccccccccccccc\n1  1  1  1          1             2             3             4             5             6     6    6    6    6 \n1  1  1  1          1             2             3             4             5             6     6    6    6    6 \n1  1  1  1          1             2             3             4             5             6     6    6    6    6 \n1  1  1  1          1             2             3             4             5             6     6    6    6    6 \n1  1  1  1   boxed1     boxed2     boxed3     boxed4     boxed5     boxed6    6    6    6    6 \n2  2  2  2   boxed2     boxed4     boxed6     boxed8    boxed10    boxed12   12   12   12   12 \n3  3  3  3   boxed3     boxed6     boxed9    boxed12    boxed15    boxed18   18   18   18   18 \n4  4  4  4   boxed4     boxed8    boxed12    boxed16    boxed20    boxed24   24   24   24   24 \n5  5  5  5   boxed5    boxed10    boxed15    boxed20    boxed25    boxed30   30   30   30   30 \n6  6  6  6   boxed6    boxed12    boxed18    boxed24    boxed30    boxed36   36   36   36   36 \n6  6  6  6          6            12            18            24            30            36    36   36   36   36 \n6  6  6  6          6            12            18            24            30            36    36   36   36   36 \n6  6  6  6          6            12            18            24            30            36    36   36   36   36 \n6  6  6  6          6            12            18            24            30            36    36   36   36   36\n endarray\n","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:circular,4,4)) yields","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"boxed\nbeginarrayccccccccccccc\n9   12  15  18          3           6            9            12            15           18   3   6   9  12 \n12  16  20  24          4           8           12            16            20           24   4   8  12  16 \n15  20  25  30          5          10           15            20            25           30   5  10  15  20 \n18  24  30  36          6          12           18            24            30           36   6  12  18  24 \n3    4   5   6   boxed1   boxed2    boxed3    boxed4    boxed5     boxed6   1   2   3   4 \n6    8  10  12   boxed2   boxed4    boxed6    boxed8    boxed10    boxed12  2   4   6   8 \n9   12  15  18   boxed3   boxed6    boxed9    boxed12   boxed15    boxed18  3   6   9  12 \n12  16  20  24   boxed4   boxed8    boxed12   boxed16   boxed20    boxed24  4   8  12  16 \n15  20  25  30   boxed5   boxed10   boxed15   boxed20   boxed25    boxed30  5  10  15  20 \n18  24  30  36   boxed6   boxed12   boxed18   boxed24   boxed30    boxed36  6  12  18  24 \n3    4   5   6          1            2            3            4             5            6   1   2   3   4 \n6    8  10  12          2            4            6            8            10           12   2   4   6   8 \n9   12  15  18          3            6            9           12            15           18   3   6   9  12 \n12  16  20  24          4            8           12           16            20           24   4   8  12  16\nendarray\n","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:symmetric,4,4)) yields","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"boxed\nbeginarrayccccccccccccc\n16  12   8  4          4            8           12            16           20          24   24  20  16  12 \n12   9   6  3          3            6           9             12           15          18   18  15  12   9 \n 8   6   4  2          2            4           6             8            10          12   12  10   8   6 \n 4   3   2  1          1            2           3             4            5           6     6   5   4   3 \n 4   3   2  1   boxed1    boxed2   boxed3     boxed4   boxed5    boxed6    6   5   4   3 \n 8   6   4  2   boxed2    boxed4   boxed6     boxed8   boxed10   boxed12  12  10   8   6 \n12   9   6  3   boxed3    boxed6   boxed9    boxed12   boxed15   boxed18  18  15  12   9 \n16  12   8  4   boxed4    boxed8   boxed12   boxed16   boxed20   boxed24  24  20  16  12 \n20  15  10  5   boxed5   boxed10   boxed15   boxed20   boxed25   boxed30  30  25  20  15 \n24  18  12  6   boxed6   boxed12   boxed18   boxed24   boxed30   boxed36  36  30  24  18 \n24  18  12  6          6           12           18           24           30           36   36  30  24  18 \n20  15  10  5          5           10           15           20           25           30   30  25  20  15 \n16  12   8  4          4            8           12           16           20           24   24  20  16  12 \n12   9   6  3          3            6            9           12           15           18   18  15  12   9\nendarray\n","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:reflect,4,4)) yields","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"boxed\nbeginarrayccccccccccccc\n25  20  15  10          5           10           15            20            25           30   25  20  15  10 \n20  16  12   8          4           8            12            16            20           24   20  16  12   8 \n15  12   9   6          3           6             9            12            15           18   15  12   9   6 \n10   8   6   4          2           4             6            8             10           12   10   8   6   4 \n5    4   3   2   boxed1   boxed2     boxed3    boxed4     boxed5    boxed6    5   4   3   2 \n10   8   6   4   boxed2   boxed4     boxed6    boxed8     boxed10   boxed12  10   8   6   4 \n15  12   9   6   boxed3   boxed6     boxed9    boxed12    boxed15   boxed18  15  12   9   6 \n20  16  12   8   boxed4   boxed8     boxed12   boxed16    boxed20   boxed24  20  16  12   8 \n25  20  15  10   boxed5   boxed10    boxed15   boxed20    boxed25   boxed30  25  20  15  10 \n30  24  18  12   boxed6   boxed12    boxed18   boxed24    boxed30   boxed36  30  24  18  12 \n25  20  15  10          5           10            15           20            25           30   25  20  15  10 \n20  16  12   8          4           8             12           16            20           24   20  16  12   8 \n15  12   9   6          3           6              9           12            15           18   15  12   9   6 \n10   8   6   4          2           4              6            8            10           12   10   8   6   4\nendarray\n","category":"page"},{"location":"padarrays/#Examples-with-Fill","page":"Padding arrays","title":"Examples with Fill","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Fill(0,(4,4),(4,4))) yields","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"boxed\nbeginarrayccccccccccccc\n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0   boxed1   boxed2    boxed3    boxed4    boxed5     boxed6   0  0  0  0 \n0  0  0  0   boxed2   boxed4    boxed6    boxed8    boxed10    boxed12  0  0  0  0 \n0  0  0  0   boxed3   boxed6    boxed9    boxed12   boxed15    boxed18  0  0  0  0 \n0  0  0  0   boxed4   boxed8    boxed12   boxed16   boxed20    boxed24  0  0  0  0 \n0  0  0  0   boxed5   boxed10   boxed15   boxed20   boxed25    boxed30  0  0  0  0 \n0  0  0  0   boxed6   boxed12   boxed18   boxed24   boxed30    boxed36  0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0 \n0  0  0  0          0           0            0            0            0             0    0  0  0  0\nendarray\n","category":"page"},{"location":"padarrays/#D-Examples-2","page":"Padding arrays","title":"3D Examples","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"Each example is based on a multi-dimensional array mathsfA inmathbbR^2 times 2 times 2 given by:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"mathsfA(1) =\nboxed\nbeginarraycc\n1  2 \n3  4\nendarray\nquad\ntextand\nquad\nmathsfA(2) =\nboxed\nbeginarraycc\n5  6 \n7  8\nendarray","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"Note that each example will yield a new multi-dimensional array mathsfA in mathbbR^4 times 4 times 4 of type OffsetArray, where prepended dimensions may be negative or start from zero.","category":"page"},{"location":"padarrays/#Examples-with-Pad-2","page":"Padding arrays","title":"Examples with Pad","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:replicate, 1, 1, 1)) gives:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"beginaligned\nmathsfA(0)  =\nboxed\nbeginarraycccc\n1  1  2  2 \n1  1  2  2 \n3  3  4  4 \n3  3  4  4\nendarray\n\nmathsfA(1)  =\nboxed\nbeginarraycccc\n1          1           2   2 \n1   boxed1   boxed2  2 \n3   boxed3   boxed4  4 \n3          3           4   4\nendarray \nmathsfA(2)  =\nboxed\nbeginarraycccc\n5          5           6   6 \n5   boxed5   boxed6  6 \n7   boxed7   boxed8  8 \n7          7           8   8\nendarray\n\nmathsfA(3)  =\nboxed\nbeginarraycccc\n5  5  6  6 \n5  5  6  6 \n7  7  8  8 \n7  7  8  8\nendarray\nendaligned\n","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:circular, 1, 1, 1)) gives:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"beginaligned\nmathsfA(0)  =\nboxed\nbeginarraycccc\n8  7  8  7 \n6  5  6  5 \n8  7  8  7 \n6  5  6  5\nendarray\n\nmathsfA(1)  =\nboxed\nbeginarraycccc\n4          3           4   3 \n2   boxed1   boxed2  1 \n4   boxed3   boxed4  3 \n2          1           2   1\nendarray \nmathsfA(2)  =\nboxed\nbeginarraycccc\n8          7           8   7 \n6   boxed5   boxed6  5 \n8   boxed7   boxed8  7 \n6          5           6   5\nendarray\n\nmathsfA(3)  =\nboxed\nbeginarraycccc\n4  3  4  3 \n2  1  2  1 \n4  3  4  3 \n2  1  2  1\nendarray\nendaligned\n","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A,Pad(:symmetric, 1, 1, 1)) gives:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"beginaligned\nmathsfA(0)  =\nboxed\nbeginarraycccc\n1  1  2  2 \n1  1  2  2 \n3  3  4  4 \n3  3  4  4\nendarray\n\nmathsfA(1)  =\nboxed\nbeginarraycccc\n1          1           2   2 \n1   boxed1   boxed2  2 \n2   boxed3   boxed4  4 \n2          3           4   4\nendarray \nmathsfA(2)  =\nboxed\nbeginarraycccc\n5          5           6   6 \n5   boxed5   boxed6  6 \n7   boxed7   boxed8  8 \n7          7           8   8\nendarray\n\nmathsfA(3)  =\nboxed\nbeginarraycccc\n5  5  6  6 \n5  5  6  6 \n7  7  8  8 \n7  7  8  8\nendarray\nendaligned\n","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Pad(:reflect, 1, 1, 1)) gives:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"beginaligned\nmathsfA(0)  =\nboxed\nbeginarraycccc\n8  7  8  7 \n6  5  6  5 \n8  7  8  7 \n6  5  6  5\nendarray\n\nmathsfA(1)  =\nboxed\nbeginarraycccc\n4          3           4   3 \n2   boxed1   boxed2  1 \n4   boxed3   boxed4  3 \n2          1           2   1\nendarray \nmathsfA(2)  =\nboxed\nbeginarraycccc\n8          7           8   7 \n6   boxed5   boxed6  5 \n8   boxed7   boxed8  7 \n6          5           6   5\nendarray\n\nmathsfA(3)  =\nboxed\nbeginarraycccc\n4  3  4  3 \n2  1  2  1 \n4  3  4  3 \n2  1  2  1\nendarray\nendaligned\n","category":"page"},{"location":"padarrays/#Examples-with-Fill-2","page":"Padding arrays","title":"Examples with Fill","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"The command padarray(A, Fill(0, (1, 1, 1))) gives:","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"beginaligned\nmathsfA(0)  =\nboxed\nbeginarraycccc\n0  0  0  0 \n0  0  0  0 \n0  0  0  0 \n0  0  0  0\nendarray\n\nmathsfA(1)  =\nboxed\nbeginarraycccc\n0          0           0   0 \n0   boxed1   boxed2  0 \n0   boxed3   boxed4  0 \n0          0           0   0\nendarray \nmathsfA(2)  =\nboxed\nbeginarraycccc\n0          0           0   0 \n0   boxed5   boxed6  0 \n0   boxed7   boxed8  0 \n0          0           0   0\nendarray\n\nmathsfA(3)  =\nboxed\nbeginarraycccc\n0  0  0  0 \n0  0  0  0 \n0  0  0  0 \n0  0  0  0\nendarray\nendaligned\n","category":"page"},{"location":"padarrays/#BorderArray","page":"Padding arrays","title":"BorderArray","text":"","category":"section"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"BorderArray(inner::AbstractArray, border::AbstractBorder) <: AbstractArray","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"Construct a thin wrapper around the array inner, with given border. No data is copied in the constructor. Instead, border values are computed on the fly in getindex calls. ","category":"page"},{"location":"padarrays/","page":"Padding arrays","title":"Padding arrays","text":"Useful for stencil computations.","category":"page"},{"location":"filters/#Filtering-images","page":"Filtering images","title":"Filtering images","text":"","category":"section"},{"location":"filters/#Introduction","page":"Filtering images","title":"Introduction","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The ImageFilters.jl package provides tools for applying transformations to arrays, with a particular focus on the kinds of operations used in image processing, such as blurring, sharpening, and edge-enhancement.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The term filtering emerges in the context of a Fourier transformation of an image, which maps an image from its canonical spatial domain to its concomitant frequency domain. Manipulating an image in the frequency domain amounts to retaining or discarding particular frequency components —- a process analogous to sifting or filtering [1]. Because the Fourier transform establishes a link between the spatial and frequency representation of an image, one can interpret various image manipulations in the spatial domain as filtering operations which accept or reject specific frequencies.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The phrase spatial filtering is often used to emphasize that an operation is, at least conceptually, devised in the context of the spatial domain of an image. We further distinguish between linear and non-linear spatial filtering. A filter is called linear if the operation performed on the pixels is linear, and is labeled non-linear otherwise.","category":"page"},{"location":"filters/#Function-options","page":"Filtering images","title":"Function options","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The imfilter() function filters a one, two or multidimensional array img with a kernel by computing their correlation.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The syntax for imfilter() is as follows:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter([T], img, kernel, [border=\"replicate\"], [alg])\nimfilter([r], img, kernel, [border=\"replicate\"], [alg])\nimfilter(r, T, img, kernel, [border=\"replicate\"], [alg])","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The following subsections describe valid options for the function arguments in more detail.","category":"page"},{"location":"filters/#Choices-for-r","page":"Filtering images","title":"Choices for r","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Optionally, you can dispatch to different implementations by passing in a resource r as defined by the ComputationalResources package.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"For example:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter(ArrayFireLibs(), img, kernel)","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"would request that the computation be performed on the GPU using the ArrayFire libraries.","category":"page"},{"location":"filters/#Choices-for-T","page":"Filtering images","title":"Choices for T","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Optionally, you can control the element type of the output image by passing in a type T as the first argument.","category":"page"},{"location":"filters/#Choices-for-img","page":"Filtering images","title":"Choices for img","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"You must provide a one, two, or multidimensional array as the input image.","category":"page"},{"location":"filters/#Choices-for-kernel","page":"Filtering images","title":"Choices for kernel","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The kernel[0, 0,..] parameter corresponds to the origin (zero displacement) of the kernel; you can use centered to place the origin at the array center, or use the OffsetArrays package to set kernel's indices manually. For example, to filter with a random centered 3x3 kernel, you could use either of the following:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"kernel = centered(rand(3,3))\nkernel = OffsetArray(rand(3,3), -1:1, -1:1)","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The kernel parameter can be specified as an array or as a \"factored kernel\", a tuple (filt1, filt2, ...) of filters to apply along each axis of the image. In cases where you know your kernel is separable, this format can speed processing. Each of these should have the same dimensionality as the image itself, and be shaped in a manner that indicates the filtering axis, e.g., a 3x1 filter for filtering the first dimension and a 1x3 filter for filtering the second dimension. In two dimensions, any kernel passed as a single matrix is checked for separability; if you want to eliminate that check, pass the kernel as a single-element tuple, (kernel,).","category":"page"},{"location":"filters/#Choices-for-border","page":"Filtering images","title":"Choices for border","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"At the image edge, border is used to specify the padding which will be used to extrapolate the image beyond its original bounds. ","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"As an indicative example of each option, the results of the padding are illustrated on an image consisting of a row of six pixels which are specified alphabetically: ","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"        ┏━━━━━━┓ \n        ┃abcdef┃ \n        ┗━━━━━━┛ ","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"We show the effects of padding only on the left and right border, but analogous consequences hold for the top and bottom border.","category":"page"},{"location":"filters/#\"replicate\"-(default)","page":"Filtering images","title":"\"replicate\" (default)","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The border pixels extend beyond the image boundaries.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"   ╭────┏━━━━━━┓────╮\n   │aaaa┃abcdef┃ffff│\n   ╰────┗━━━━━━┛────╯","category":"page"},{"location":"filters/#\"circular\"","page":"Filtering images","title":"\"circular\"","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"\n   ╭────┏━━━━━━┓────╮\n   │cdef┃abcdef┃abcd│\n   ╰────┗━━━━━━┛────╯\n","category":"page"},{"location":"filters/#\"reflect\"","page":"Filtering images","title":"\"reflect\"","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"\n   ╭────┏━━━━━━┓────╮\n   │dcba┃abcdef┃fedc│\n   ╰────┗━━━━━━┛────╯\n","category":"page"},{"location":"filters/#\"symmetric\"","page":"Filtering images","title":"\"symmetric\"","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The border pixels reflect relative to the edge itself.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"\n   ╭────┏━━━━━━┓────╮\n   │edcb┃abcdef┃edcb│\n   ╰────┗━━━━━━┛────╯\n","category":"page"},{"location":"filters/#Fill(m)","page":"Filtering images","title":"Fill(m)","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The border pixels are filled with a specified value m.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"\n   ╭────┏━━━━━━┓────╮\n   │mmmm┃abcdef┃mmmm│\n   ╰────┗━━━━━━┛────╯\n","category":"page"},{"location":"filters/#Inner()","page":"Filtering images","title":"Inner()","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Indicate that edges are to be discarded in filtering, only the interior of the result is to be returned.","category":"page"},{"location":"filters/#NA()","page":"Filtering images","title":"NA()","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Choose filtering using \"NA\" (Not Available) boundary conditions. This is most appropriate for filters that have only positive weights summing to 1, such as blurring filters–-rather than \"make up\" values beyond the edges, the result is normalized by the number of in-bounds pixels (similar to nanmean).","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"For example:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"julia> img = [0, 0, 1, 0, 0, 0, 1];\n\njulia> imfilter(img, centered([1, 1, 1]/3), NA())\n7-element Vector{Float64}:\n 0.0\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n 0.0\n 0.3333333333333333\n 0.5","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"See also: Pad, padarray, Inner, NA  and NoPad","category":"page"},{"location":"filters/#Choices-for-alg","page":"Filtering images","title":"Choices for alg","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The alg parameter allows you to choose the particular algorithm: Algorithm.FIR() (finite impulse response, aka traditional digital filtering) or Algorithm.FFT() (Fourier-based filtering). If no choice is specified, one will be chosen based on the size of the image and kernel in a way that strives to deliver good performance. Alternatively you can use a custom filter type, like KernelFactors.IIRGaussian.","category":"page"},{"location":"filters/#Convolution-versus-correlation","page":"Filtering images","title":"Convolution versus correlation","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The default operation of imfilter is correlation. ","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"In the following example, consider the image matrix f and a centered filter coefficient mask w.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The specification Fill(0, w) indicates that we wish to pad the border of f with zeros. The amount of padding is automatically determined by considering the length of w.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"# Create a two-dimensional discrete unit impulse function.\nf = fill(0, (9, 9));\nf[5, 5] = 1\n\n# Specify a filter coefficient mask and set the center of the mask as the origin.\nw = centered([1 2 3; 4 5 6 ; 7 8 9]);","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"By reflecting w we compute the convolution of f and w. Compare the correlation and convolution:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"correlation = imfilter(f, w, Fill(0, w))\nconvolution = imfilter(f, reflect(w), Fill(0, w))","category":"page"},{"location":"filters/#Miscellaneous-border-padding-options","page":"Filtering images","title":"Miscellaneous border padding options","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Given the following example values:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"f = reshape(1.0:81.0, 9, 9)\nw = centered(reshape(1.0:9.0, 3, 3))","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"you can designate the type of padding by supplying an appropriate string:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter(f, w, \"replicate\")\nimfilter(f, w, \"circular\")\nimfilter(f, w, \"symmetric\")\nimfilter(f, w, \"reflect\")","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Alternatively, you can explicitly use the Pad type to designate the padding style:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter(f, w, Pad(:replicate))\nimfilter(f, w, Pad(:circular))\nimfilter(f, w, Pad(:symmetric))\nimfilter(f, w, Pad(:reflect))","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"If you want to pad with a specific value, use the Fill type.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter(f, w, Fill(0, w))\nimfilter(f, w, Fill(1, w))\nimfilter(f, w, Fill(-1, w))","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Specify Inner() if you want to retrieve the interior sub-array of f for which the filtering operation is defined without padding:","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter(f, w, Inner())","category":"page"},{"location":"filters/#The-imfilter!-function","page":"Filtering images","title":"The imfilter! function","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The imfilter!() function filters an array img with kernel kernel by computing their correlation, storing the result in imgfilt.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"imfilter!(imgfilt, img, kernel, [border=\"replicate\"], [alg])\nimfilter!(r, imgfilt, img, kernel, border::Pad)\nimfilter!(r, imgfilt, img, kernel, border::NoPad, [inds=axes(imgfilt)])","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"The indices of imgfilt determine the region over which the filtered image is computed – you can use this fact to select just a specific region of interest, although be aware that the input img might still get padded.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"Alteratively, explicitly provide the indices inds of imgfilt that you want to calculate, and use NoPad boundary conditions. In such cases, you are responsible for supplying appropriate padding: img must be indexable for all of the locations needed for calculating the output. This syntax is best-supported for FIR filtering; in particular, the IIR filtering can lead to results that are inconsistent with respect to filtering the entire array.","category":"page"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"See also: imfilter, centered, padarray, Pad, Fill, Inner, KernelFactors.IIRGaussian.","category":"page"},{"location":"filters/#References","page":"Filtering images","title":"References","text":"","category":"section"},{"location":"filters/","page":"Filtering images","title":"Filtering images","text":"R. C. Gonzalez and R. E. Woods. Digital Image Processing (3rd Edition).  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.","category":"page"},{"location":"demos/filters/min_max_filter/#Max-min-filters","page":"Max min filters","title":"Max min filters","text":"","category":"section"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"(Image: Source code) (Image: Author) (Image: Update time)","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"In this tutorial we see how can we can effectively use max and min filter to distinguish between smooth and texture edges  in grayscale images.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"We will use the mapwindow function in ImageFiltering.jl which provides a general functionality to apply any function to the window around each pixel.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"using ImageCore, ImageShow, ImageFiltering\nusing TestImages\n\nimg = Gray.(testimage(\"house\");)      # Original Image","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"We can use the minimum function to compute the minimum of the grayscale values in the given matrix or array. For example:","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"minimum([Gray(0.7),Gray(0.5),Gray(0.0)]) # Should return Gray(0.0) i.e black.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"filter_size = (15, 15)\n# Using the `mapwindow` function, we create an image of the local minimum.\n# `mapwindow` maps the given function over a moving window of given size.\nimg_min = mapwindow(minimum, img, filter_size)\n# Similarly for maximum\nimg_max = mapwindow(maximum, img, filter_size)\n# The max(min) filter\nimg_max_min = mapwindow(maximum, img_min, filter_size)\n# The min(max) filter\nimg_min_max = mapwindow(minimum, img_max, filter_size)\nmosaicview(img_min, img_max, img_max_min, img_min_max; nrow=1)","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"Now that we are done with the basic filtered images, we proceed to the next part which is edge detection using these filters.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"For edge detection, we need to define thresholds for our image. The threshold is an important tool to binarize a grayscale image. The threshold value for a given pixel practically decides if the pixel visible or not in the output image. However, appyling a global threshold might not consider the variation of colors/brightness within the image. Thus we consider an adaptive type theresholding method here using max/min results.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"The max(min) and min(max) filter effectively follows the smooth edges of the image. Therefore, their average also follows the smooth parts of the image. If we use this image as a threshold for the original image, the smooth parts of the original image will get filtered out, leaving only the texture and/or noise behind. So we can use the average of img_max_min and img_min_max as the texture threshold.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"The average of min and max filters also gives us the smooth edges, but it also includes the noise in the image. So using average of img_min and img_max as a threshold will yeild only texture.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"img_texture_noise_threshold = (img_max_min + img_max_min) ./ 2\nimg_texture_threshold = (img_max + img_min) ./ 2\nmosaicview(img_texture_noise_threshold, img_texture_threshold; nrow=1)","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"# The Dynamic Gist is obtained by subtracting the img_texture_threshold from the original image.\n# The filtered image gives us the texture of the image.\nimg_dynamic_gist = img - img_texture_threshold\n# The Texture Gist is obtained by subtracting img_texture_noise_threshold from the original image.\n# The filtered image gives us the texture along with the noise of the image.\nimg_texture_gist = img - img_texture_noise_threshold\nmosaicview(img_dynamic_gist, img_texture_gist; nrow=1)","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"# We extract out the smooth/ramp parts of the image.\n# The darker section of the image consist of the ramp edges. The brighter pixels are mostly noise.\nramp = img_dynamic_gist - img_texture_gist\n# Filtered-out edges\nedge = img_max - img_min\n# Smoothed-out version of edge\nedge_smoothed = img_min_max - img_max_min\nmosaicview(img, ramp, edge, edge_smoothed; nrow=2)","category":"page"},{"location":"demos/filters/min_max_filter/#References","page":"Max min filters","title":"References","text":"","category":"section"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"Verbeek, P. W., Vrooman, H. A., & Van Vliet, L. J. (1988). Low-level image processing by max-min filters. Signal Processing, 15(3), 249-258.","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"","category":"page"},{"location":"demos/filters/min_max_filter/","page":"Max min filters","title":"Max min filters","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"kernels/#Kernels","page":"Kernels","title":"Kernels","text":"","category":"section"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"Kernel is a module implementing filtering (correlation) kernels of full dimensionality.","category":"page"},{"location":"kernels/#Supported-kernels","page":"Kernels","title":"Supported kernels","text":"","category":"section"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"The following kernels are supported:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"sobel\nprewitt\nando3, ando4, and ando5\nscharr\nbickley\ngaussian\nDoG (Difference-of-Gaussian)\nLoG (Laplacian-of-Gaussian)\nLaplacian\ngabor\nmoffat","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"KernelFactors is a module implementing separable filtering kernels, each stored in terms of their factors. The following kernels are supported:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"box\nsobel\nprewitt\nando3, ando4, and ando5 (the latter in 2d only)\nscharr\nbickley\ngaussian\nIIRGaussian (approximate gaussian filtering, fast even for large σ)","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"The two modules Kernel and KernelFactors implement popular correlation kernels in \"dense\" and \"factored\" forms, respectively. Type ?Kernel or ?KernelFactors at the REPL to see which kernels are supported.","category":"page"},{"location":"kernels/#Correlation,-not-convolution","page":"Kernels","title":"Correlation, not convolution","text":"","category":"section"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"The ImageFiltering package uses the following formula to calculate the filtered image F from an input image A and kernel K:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"FI = sum_J AI+J KJ","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"Consequently, the resulting image is the correlation, not convolution, of the input and the kernel. If you want the convolution, first call reflect on the kernel.","category":"page"},{"location":"kernels/#Kernel-indices","page":"Kernels","title":"Kernel indices","text":"","category":"section"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"ImageFiltering exploits Julia's ability to define arrays whose indices span an arbitrary range:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"julia> Kernel.gaussian(1)\nOffsetArray{Float64,2,Array{Float64,2}} with indices -2:2×-2:2:\n 0.00296902  0.0133062  0.0219382  0.0133062  0.00296902\n 0.0133062   0.0596343  0.0983203  0.0596343  0.0133062\n 0.0219382   0.0983203  0.162103   0.0983203  0.0219382\n 0.0133062   0.0596343  0.0983203  0.0596343  0.0133062\n 0.00296902  0.0133062  0.0219382  0.0133062  0.00296902","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"The indices of this array span the range -2:2 along each axis, and the center of the gaussian is at position [0,0]. As a consequence, this filter \"blurs\" but does not \"shift\" the image; were the center instead at, say, [3,3], the filtered image would be shifted by 3 pixels downward and to the right compared to the original.","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"The centered function is a handy utility for converting an ordinary array to one that has coordinates [0,0,...] at its center position:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"julia> centered([1 0 1; 0 1 0; 1 0 1])\nOffsetArray{Int64,2,Array{Int64,2}} with indices -1:1×-1:1:\n 1  0  1\n 0  1  0\n 1  0  1","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"See OffsetArrays for more information.","category":"page"},{"location":"kernels/#Factored-kernels","page":"Kernels","title":"Factored kernels","text":"","category":"section"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"A key feature of Gaussian kernels–-along with many other commonly-used kernels–-is that they are separable, meaning that K[j_1,j_2,...] can be written as K_1j_1 K_2j_2 cdots. As a consequence, the correlation:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"Fi_1i_2 = sum_j_1j_2 Ai_1+j_1i_2+j_2 Kj_1j_2","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"can be written:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"Fi_1i_2 = sum_j_2 left(sum_j_1 Ai_1+j_1i_2+j_2 K_1j_1right) K_2j_2","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"If the kernel is of size m×n, then the upper version line requires mn operations for each point of filtered, whereas the lower version requires m+n operations. Especially when m and n are larger, this can result in a substantial savings.","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"To enable efficient computation for separable kernels, imfilter accepts a tuple of kernels, filtering the image by each sequentially. You can either supply m×1 and 1×n filters directly, or (somewhat more efficiently) call kernelfactors on a tuple-of-vectors:","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"julia> kern1 = centered([1/3, 1/3, 1/3])\nOffsetArray{Float64,1,Array{Float64,1}} with indices -1:1:\n 0.333333\n 0.333333\n 0.333333\n\njulia> kernf = kernelfactors((kern1, kern1))\n(ImageFiltering.KernelFactors.ReshapedOneD{Float64,2,0,OffsetArray{Float64,1,Array{Float64,1}}}([0.333333,0.333333,0.333333]),ImageFiltering.KernelFactors.ReshapedOneD{Float64,2,1,OffsetArray{Float64,1,Array{Float64,1}}}([0.333333,0.333333,0.333333]))\n\njulia> kernp = broadcast(*, kernf...)\nOffsetArray{Float64,2,Array{Float64,2}} with indices -1:1×-1:1:\n 0.111111  0.111111  0.111111\n 0.111111  0.111111  0.111111\n 0.111111  0.111111  0.111111\n\njulia> imfilter(img, kernf) ≈ imfilter(img, kernp)\ntrue","category":"page"},{"location":"kernels/","page":"Kernels","title":"Kernels","text":"If the kernel is a two dimensional array, imfilter will attempt to factor it; if successful, it will use the separable algorithm. You can prevent this automatic factorization by passing the kernel as a tuple, e.g., as (kernp,).","category":"page"},{"location":"demos/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"demos/#Filters","page":"Examples","title":"Filters","text":"","category":"section"},{"location":"demos/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"With median filter as an example, this demo shows how you could construct a custom kernel and pass it to mapwindow for common stencil operations.","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"Custom median filters","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"In this tutorial we see how can we can effectively use max and min filter to distinguish between smooth and texture edges  in grayscale images.","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"Max min filters","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"demos/#Search","page":"Examples","title":"Search","text":"","category":"section"},{"location":"demos/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"This demo shows how to find objects in an image using template matching. ","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"Template Matching","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"demos/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"demos/filters/median_filter/#Custom-median-filters","page":"Custom median filters","title":"Custom median filters","text":"","category":"section"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"(Image: Source code) (Image: Author) (Image: Update time)","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"With median filter as an example, this demo shows how you could construct a custom kernel and pass it to mapwindow for common stencil operations.","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"Unlike other image processing toolboxes, ImageFiltering.jl does not provide you an out-of-box function for median filters. It instead provides the more general mapwindow function, which allows you to apply any function to the window around each pixel.","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"using ImageFiltering, ImageCore, ImageShow # or you could just `using Images`\nusing TestImages\nusing Statistics\nusing Random #hide\nRandom.seed!(0) #hide\n\nimg = Float64[isodd(i) - isodd(j) for i = 1:5, j = 1:5]\nimg[3, 3] = 1000\nimg #hide","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"patch_size = (3, 3)\nimgm = mapwindow(median, img, patch_size)","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"mapwindow provides a high-level interface to loop over the image and call a function (median in this demo) on each patch/window. It's performing an operation that is nearly equivalent to the loop below, albeit more efficiently:","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"# For simplicity, border condition is not included here.\nimgm = zeros(axes(img))\nR = CartesianIndices(img)\nI_first, I_last = first(R), last(R)\nΔ = CartesianIndex(patch_size .÷ 2)\nfor I in R\n    patch = max(I_first, I-Δ):min(I_last, I+Δ)\n    imgm[I] = median(img[patch])\nend\nimgm","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"Compared to this hand-written loop, mapwindow offers additional flexibility in handling the borders and allows you to process only a subset of the windows. For some functions (e.g., min, max, and extrema), mapwindow uses a custom implementation that is far more efficient than naively computing the function \"freshly\" on each window.","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"When the input array has NaN or some unwanted pixel values, a pre-filtering process is needed to exclude them first. This can be done quite easily by compositing a given kernel operation and a filter operation. Let's still take median filter as an example.","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"img[2,2] = NaN\nimgm = mapwindow(median, img, (3,3))","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"NaN has polluted the output, which is usually not wanted. This can be fixed quite easily by compositing a new filter kernel. This way, we only compute the median value on the non-NaN subset of each patch/window.","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"_median(patch) = median(filter(x->!isnan(x), patch))\nimgm = mapwindow(_median, img, patch_size)","category":"page"},{"location":"demos/filters/median_filter/#Impulse-(Salt-and-Pepper)-noise-removal","page":"Custom median filters","title":"Impulse (Salt and Pepper) noise removal","text":"","category":"section"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"Median filters are quite robust to outliers (unusual values), this property can be used to remove salt&pepper noise. An image with n-level salt&papper noise is defined as: each pixel p has n/2 probabilty to be filled by 0(the minimal gamut value), n/2 probabilty to be filled by 1(the maximal gamut value), and 1-n probablity to be undamaged.","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"img = testimage(\"cameraman\")\n\nn = 0.2 # noise level\nnoisy_img = map(img) do p\n    sp = rand()\n    if sp < n/2\n        eltype(img)(gamutmin(eltype(img))...)\n    elseif sp < n\n        eltype(img)(gamutmax(eltype(img))...)\n    else\n        p\n    end\nend\n\ndenoised_img = mapwindow(median!, noisy_img, (5, 5))\n\nmosaicview(img, noisy_img, denoised_img; nrow=1)","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"","category":"page"},{"location":"demos/filters/median_filter/","page":"Custom median filters","title":"Custom median filters","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"tutorials/tutorial1/#Tutorial","page":"Tutorial 1","title":"Tutorial","text":"","category":"section"},{"location":"tutorials/tutorial1/#About-this-tutorial","page":"Tutorial 1","title":"About this tutorial","text":"","category":"section"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"This is a short introduction to ImageFilters.jl, using a Pluto notebook. If you're familiar with the basics of using Pluto, you're ready to follow along.","category":"page"},{"location":"tutorials/tutorial1/#First-steps","page":"Tutorial 1","title":"First steps","text":"","category":"section"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"Open a Pluto notebook and load the following packages:","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"using ImageFiltering, TestImages, PlutoUI, ImageShow, Colors, Images","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 01)","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"We'll use the image of the mandrill from TestImages.jl:","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"img1 = testimage(\"mandrill\")","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 02)","category":"page"},{"location":"tutorials/tutorial1/#Blurring-an-image","page":"Tutorial 1","title":"Blurring an image","text":"","category":"section"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"To make a blurred version of the image, we can use a Gaussian filter kernel, using the Kernel.gaussian() function. A value of 10 is quite blurry:","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"img2 = imfilter(img1, Kernel.gaussian(10))","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 03)","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"It's also possible to use an array as a kernel. This 3 × 3 array in k is a good example of a sharpening filter: the central pixel will be boosted.","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"k = [0 -1 0 ; -1 5.5 -1 ; 0 -1 0]","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 04)","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"img3 = imfilter(img1, k)","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 05)","category":"page"},{"location":"tutorials/tutorial1/#Applying-a-function-to-each-pixel","page":"Tutorial 1","title":"Applying a function to each pixel","text":"","category":"section"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"The mapwindow() function provides a way to slide a rectangular \"window\" over every pixel, and apply a function to that pixel using the surrounding pixel values. The window can be m pixels across and n pixels down; m and n must both be odd.","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"By default every pixel is visited.","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"This example uses a 13 × 13 window, and randomly selects just one of the 169 pixels in that window as the new value for the pixel.","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"mapwindow(b -> b[rand(1:end)], img1, (13, 13))","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"The result is like a dithered/downsampled version of the image.","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 06)","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"In the next example, this short function is used to convert the buffer to gray values, find the lowest (minimum) value of the windowed area, then select the colored pixel at that point. The resulting image is thus a darker and less detailed version of the original.","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"function minimum_color(buff::T) where T <: Array\n\tgbuff = Gray.(buff)\n\tk = argmin(gbuff)\n\treturn buff[k]\nend\n\nmapwindow(minimum_color, img1, (5, 5))","category":"page"},{"location":"tutorials/tutorial1/","page":"Tutorial 1","title":"Tutorial 1","text":"(Image: pluto 07)","category":"page"},{"location":"gradients/#Image-gradients","page":"Gradients","title":"Image gradients","text":"","category":"section"},{"location":"gradients/#The-imgradients-function","page":"Gradients","title":"The imgradients function","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"This function estimate the gradient of img in the direction of the first and second dimension at all points of the image, using a kernel specified by kernelfun.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"imgradients(img, kernelfun=KernelFactors.ando3, border=\"replicate\") -> gimg1, gimg2, ...","category":"page"},{"location":"gradients/#Output","page":"Gradients","title":"Output","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The gradient is returned as a tuple-of-arrays, one for each dimension of the input; gimg1 corresponds to the derivative with respect to the first dimension, gimg2 to the second, and so on.","category":"page"},{"location":"gradients/#Example","page":"Gradients","title":"Example","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"This example compares the quality of the gradient estimation methods in terms of the accuracy with which the orientation of the gradient is estimated.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"using Images\n\nvalues = LinRange(-1,1,128);\nw = 1.6*pi;\n\n## Define a function of a sinusoidal grating, f(x,y) = sin( (w*x)^2 + (w*y)^2 ),\n## together with its exact partial derivatives.\nI = [sin( (w*x)^2 + (w*y)^2 ) for y in values, x in values];\nIx = [2*w*x*cos( (w*x)^2 + (w*y)^2 ) for y in values, x in values];\nIy = [2*w*y*cos( (w*x)^2 + (w*y)^2 ) for y in values, x in values];\n\n## Determine the exact orientation of the gradients.\ndirection_true = atan.(Iy./Ix);\n\nfor kernelfunc in (KernelFactors.prewitt, KernelFactors.sobel,\n                   KernelFactors.ando3, KernelFactors.scharr,\n                   KernelFactors.bickley)\n\n    ## Estimate the gradients and their orientations.\n    Gy, Gx = imgradients(I,kernelfunc, \"replicate\");\n    direction_estimated = atan.(Gy./Gx);\n\n    ## Determine the mean absolute deviation between the estimated and true\n    ## orientation. Ignore the values at the border since we expect them to be\n    ## erroneous.\n    error = mean(abs.(direction_true[2:end-1,2:end-1] -\n                     direction_estimated[2:end-1,2:end-1]));\n\n    error = round(error, digits=5);\n    println(\"Using \\$kernelfunc results in a mean absolute deviation of \\$error\")\nend","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The output of this code is:","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"Using ImageFiltering.KernelFactors.prewitt results in a mean absolute deviation of 0.01069\nUsing ImageFiltering.KernelFactors.sobel results in a mean absolute deviation of 0.00522\nUsing ImageFiltering.KernelFactors.ando3 results in a mean absolute deviation of 0.00365\nUsing ImageFiltering.KernelFactors.scharr results in a mean absolute deviation of 0.00126\nUsing ImageFiltering.KernelFactors.bickley results in a mean absolute deviation of 0.00038","category":"page"},{"location":"gradients/#kernelfun-options","page":"Gradients","title":"kernelfun options","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"You can specify your choice of the finite-difference scheme via the kernelfun parameter. You can also indicate how to deal with the pixels on the border of the image with the border parameter.","category":"page"},{"location":"gradients/#Choices-for-kernelfun","page":"Gradients","title":"Choices for kernelfun","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"In general kernelfun can be any function which satisfies the following interface:","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"    kernelfun(extended::NTuple{N,Bool}, d) -> kern_d,","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"where kern_d is the kernel for producing the derivative with respect to the dth dimension of an N-dimensional array. The parameter extended[i] is true if the image is of size > 1 along dimension i. The parameter kern_d may be provided as a dense or factored kernel, with factored representations recommended when the kernel is separable.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"Some valid kernelfun options are described below.","category":"page"},{"location":"gradients/#KernelFactors.prewitt","page":"Gradients","title":"KernelFactors.prewitt","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"With the prewit option [3] the computation of the gradient is based on the kernels:","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"beginaligned\nmathbfH_x_1  = frac16\n    beginbmatrix\n    -1  -1  -1 \n    0  0  0 \n    1  1  1\n    endbmatrix\n\nmathbfH_x_2  =  frac16\n    beginbmatrix\n    -1  0  1 \n    -1  0  1 \n    -1  0  1\n    endbmatrix \n = frac16\n    beginbmatrix\n    1 \n    1  \n    1\n    endbmatrix\n    beginbmatrix\n    -1  0  1\n    endbmatrix\n\n = frac16\n    beginbmatrix\n    -1 \n    0  \n    1\n    endbmatrix\n    beginbmatrix\n    1  1  1\n    endbmatrix\nendaligned","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also: KernelFactors.prewitt and Kernel.prewitt","category":"page"},{"location":"gradients/#KernelFactors.sobel","page":"Gradients","title":"KernelFactors.sobel","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The sobel option [4] designates the kernels","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"beginaligned\nmathbfH_x_1  = frac18\n    beginbmatrix\n    -1  -2  -1 \n     0  0  0 \n     1  2  1\n    endbmatrix\n\nmathbfH_x_2  = frac18\n    beginbmatrix\n    -1  0  1 \n    -2  0  2 \n    -1  0  1\n    endbmatrix \n = frac18\n    beginbmatrix\n    -1 \n    0  \n    1\n    endbmatrix\n    beginbmatrix\n    1  2  1\n    endbmatrix\n\n = frac18\n    beginbmatrix\n    1 \n    2  \n    1\n    endbmatrix\n    beginbmatrix\n    -1  0  1\n    endbmatrix\nendaligned","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also:  KernelFactors.sobel and Kernel.sobel","category":"page"},{"location":"gradients/#KernelFactors.ando3","page":"Gradients","title":"KernelFactors.ando3","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The ando3 option [5] specifies the kernels","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"beginaligned\nmathbfH_x_1   =\n    beginbmatrix\n    -0112737  -0274526  -0112737 \n     0  0  0 \n     0112737  0274526  0112737\n    endbmatrix\n\nmathbfH_x_2   =\n    beginbmatrix\n    -0112737  0  0112737 \n    -0274526  0  0274526 \n    -0112737  0  0112737\n    endbmatrix \n  = beginbmatrix\n    -1 \n    0  \n    1\n    endbmatrix\n    beginbmatrix\n    0112737  0274526  0112737\n    endbmatrix\n\n  = beginbmatrix\n    0112737 \n    0274526  \n    0112737\n    endbmatrix\n    beginbmatrix\n    -1  0  1\n    endbmatrix\nendaligned\n","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also: KernelFactors.ando3, and Kernel.ando3;  KernelFactors.ando4, and Kernel.ando4; KernelFactors.ando5, and Kernel.ando5","category":"page"},{"location":"gradients/#KernelFactors.scharr","page":"Gradients","title":"KernelFactors.scharr","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The scharr option [6] designates the kernels","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"beginaligned\nmathbfH_x_1  =\nfrac132\nbeginbmatrix\n-3  -10  -3 \n0  0  0 \n 3  10  3\nendbmatrix\n\nmathbfH_x_2  =\nfrac132\nbeginbmatrix\n-3  0  3 \n-10  0  10\n-3  0  3\nendbmatrix \n = frac132\nbeginbmatrix\n    -1 \n    0  \n    1\nendbmatrix\nbeginbmatrix\n    3  10  3\nendbmatrix\n\n = frac132\nbeginbmatrix\n    3 \n    10  \n    3\nendbmatrix\nbeginbmatrix\n    -1  0  1\nendbmatrix\nendaligned","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also:  KernelFactors.scharr and Kernel.scharr","category":"page"},{"location":"gradients/#KernelFactors.bickley","page":"Gradients","title":"KernelFactors.bickley","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The bickley option [7,8] designates the kernels","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"beginaligned\nmathbfH_x_1  = frac112\n    beginbmatrix\n        -1  -4  -1 \n         0  0  0 \n         1  4  1\n    endbmatrix\n\nmathbfH_x_2  = frac112\n    beginbmatrix\n        -1  0  1 \n        -4  0  4 \n        -1  0  1\n    endbmatrix \n = frac112\n    beginbmatrix\n        -1 \n        0  \n        1\n    endbmatrix\n    beginbmatrix\n        1  4  1\n    endbmatrix\n\n  = frac112\n   beginbmatrix\n        1 \n        4  \n        1\n   endbmatrix\n   beginbmatrix\n        -1  0  1\n   endbmatrix\nendaligned","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also:  KernelFactors.bickley and Kernel.bickley","category":"page"},{"location":"gradients/#Choices-for-border","page":"Gradients","title":"Choices for border","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"At the image edge, border is used to specify the padding which will be used to extrapolate the image beyond its original bounds. As an indicative example of each option the results of the padding are illustrated on an image consisting of a row of six pixels which are specified alphabetically: boxeda  b  c  d  e  f. We show the effects of padding only on the left and right border, but analogous consequences hold for the top and bottom border.","category":"page"},{"location":"gradients/#\"replicate\"","page":"Gradients","title":"\"replicate\"","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The border pixels extend beyond the image boundaries.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"boxed\nbeginarraylcr\n  a a a a    a  b  c  d  e  f  f  f  f  f\nendarray\n","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also: Pad, padarray, Inner and NoPad","category":"page"},{"location":"gradients/#\"circular\"","page":"Gradients","title":"\"circular\"","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"boxed\nbeginarraylcr\n  c d e f    a  b  c  d  e  f  a  b  c  d\nendarray\n","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also: Pad, padarray, Inner and NoPad","category":"page"},{"location":"gradients/#\"symmetric\"","page":"Gradients","title":"\"symmetric\"","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"boxed\nbeginarraylcr\n  e d c b    a  b  c  d  e  f  e  d  c  b\nendarray\n","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also: Pad, padarray, Inner and NoPad","category":"page"},{"location":"gradients/#\"reflect\"","page":"Gradients","title":"\"reflect\"","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The border pixels reflect relative to the edge itself.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"boxed\nbeginarraylcr\n  d c b a    a  b  c  d  e  f  f  e  d  c\nendarray\n","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"See also: Pad, padarray, Inner and NoPad","category":"page"},{"location":"gradients/#Details","page":"Gradients","title":"Details","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"To appreciate the difference between various gradient estimation methods it is helpful to distinguish between: (1) a continuous scalar-valued analogue image f_textrmA(x_1x_2), where x_1x_2 in mathbbR, and (2) its discrete digital realization f_textrmD(x_1x_2), where x_1x_2 in mathbbN, 1 le x_1 le M and 1 le x_2 le N.","category":"page"},{"location":"gradients/#Analogue-image","page":"Gradients","title":"Analogue image","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The gradient of a continuous analogue image f_textrmA(x_1x_2) at location (x_1x_2) is defined as the vector","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"nabla mathbff_textrmA(x_1x_2) = fracpartial\nf_textrmA(x_1x_2)partial x_1 mathbfe_1 +\nfracpartial f_textrmA(x_1x_2)partial x_2 mathbfe_2","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"where mathbfe_d (d = 12) is the unit vector in the x_d-direction. The gradient points in the direction of maximum rate of change of f_textrmA at the coordinates (x_1x_2). The gradient can be used to compute the derivative of a function in an arbitrary direction. In particular, the derivative of f_textrmA in the direction of a unit vector mathbfu is given by nabla_mathbfuf_textrmA(x_1x_2) = nabla mathbff_textrmA(x_1x_2) cdot mathbfu, where cdot denotes the dot product.","category":"page"},{"location":"gradients/#Digital-image","page":"Gradients","title":"Digital image","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"In practice, we acquire a digital image f_textrmD(x_1x_2) where the light intensity is known only at a discrete set of locations. This means that the required partial derivatives are undefined and need to be approximated using discrete difference formulae [1].","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"A straightforward way to approximate the partial derivatives is to use central-difference formulae","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":" fracpartial f_textrmD(x_1x_2)partial x_1  approx\n        fracf_textrmD(x_1+1x_2) - f_textrmD(x_1-1x_2) 2","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"and","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":" fracpartial f_textrmD(x_1x_2)partial x_2   approx\n         fracf_textrmD(x_1x_2+1) - f_textrmD(x_1x_2-1)2","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"However, the central-difference formulae are very sensitive to noise. When working with noisy image data, one can obtain a better approximation of the partial derivatives by using a suitable weighted combination of the neighboring image intensities. The weighted combination can be represented as a discrete convolution operation between the image and a kernel which characterizes the requisite weights. In particular, if h_x_d (d = 12) represents a 2r+1 times 2r+1 kernel, then","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":" fracpartial f_textrmD(x_1x_2)partial x_d  approx\nsum_i = -r^r sum_j = -r^r\nf_textrmD(x_1-ix_2-j)\n  h_x_d(ij)","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The kernel is frequently also called a mask or convolution matrix.","category":"page"},{"location":"gradients/#Weighting-schemes-and-approximation-error","page":"Gradients","title":"Weighting schemes and approximation error","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"The choice of weights determines the magnitude of the approximation error and whether the finite-difference scheme is isotropic. A finite-difference scheme is isotropic if the approximation error does not depend on the orientation of the coordinate system and anisotropic if the approximation error has a directional bias [2]. With a continuous analogue image the magnitude of the gradient would be invariant upon rotation of the coordinate system, but in practice one cannot obtain perfect isotropy with a finite set of discrete points. Hence a finite-difference scheme is typically considered isotropic if the leading error term in the approximation does not have preferred directions.","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"Most finite-difference schemes that are used in image processing are based on 3 times 3 kernels, and as noted by [7], many can also be parametrized by a single parameter alpha as follows:","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"mathbfH_x_1 =\nfrac14 + 2alpha\nbeginbmatrix\n-1  -alpha  -1 \n0  0  0 \n 1  alpha  1\nendbmatrix\nquad\ntextand\nquad\nmathbfH_x_2 =\nfrac12 + 4alpha\nbeginbmatrix\n-1  0  1 \n-alpha  0  alpha \n -1  0  1\nendbmatrix","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"where","category":"page"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"alpha =\nbegincases\n0   textSimple Finite Difference \n1   textPrewitt \n2   textSobel \n24351   textAndo \nfrac103   textScharr \n4   textBickley\nendcases","category":"page"},{"location":"gradients/#Separable-kernels","page":"Gradients","title":"Separable kernels","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"A kernel is called separable if it can be expressed as the convolution of two one-dimensional filters. With a matrix representation of the kernel, separability means that the kernel matrix can be written as an outer product of two vectors. Separable kernels offer computational advantages since instead of performing a two-dimensional convolution one can perform a sequence of one-dimensional convolutions.","category":"page"},{"location":"gradients/#References","page":"Gradients","title":"References","text":"","category":"section"},{"location":"gradients/","page":"Gradients","title":"Gradients","text":"B. Jahne, Digital Image Processing (5th ed.). Springer Publishing Company, Incorporated, 2005. 10.1007/3-540-27563-0\nM. Patra  and  M. Karttunen, \"Stencils with isotropic discretization error for differential operators,\" Numer. Methods Partial Differential Eq., vol. 22, pp. 936–953, 2006. doi:10.1002/num.20129\nJ. M. Prewitt, \"Object enhancement and extraction,\" Picture processing and Psychopictorics, vol. 10, no. 1, pp. 15–19, 1970.\nP.-E. Danielsson and O. Seger, \"Generalized and separable sobel operators,\" in  Machine Vision for Three-Dimensional Scenes,  H. Freeman, Ed.  Academic Press, 1990,  pp. 347–379. doi:10.1016/b978-0-12-266722-0.50016-6\nS. Ando, \"Consistent gradient operators,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no.3, pp. 252–265, 2000. doi:10.1109/34.841757\nH. Scharr and  J. Weickert, \"An anisotropic diffusion algorithm with optimized rotation invariance,\" Mustererkennung 2000, pp. 460–467, 2000. doi:10.1007/978-3-642-59802-9_58\nA. Belyaev, \"Implicit image differentiation and filtering with applications to image sharpening,\" SIAM Journal on Imaging Sciences, vol. 6, no. 1, pp. 660–679, 2013. doi:10.1137/12087092x\nW. G. Bickley, \"Finite difference formulae for the square lattice,\" The Quarterly Journal of Mechanics and Applied Mathematics, vol. 1, no. 1, pp. 35–42, 1948.  doi:10.1093/qjmam/1.1.35","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"DocTestSetup = quote\n    using Colors, ImageFiltering, TestImages\n    img = testimage(\"mandrill\")\nend","category":"page"},{"location":"#ImageFiltering.jl","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"","category":"section"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"ImageFiltering supports linear and nonlinear filtering operations on arrays, with an emphasis on the kinds of operations used in image processing.","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"The main functions provided by this package are:","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"Function Action\nimfilter Filter a one, two or multidimensional array img with a kernel by computing their correlation\nimfilter! Filter an array img with kernel kernel by computing their correlation, storing the result in imgfilt\nmapwindow Apply a function to sliding windows of img\nmapwindow! A variant of mapwindow with preallocated output\nimgradients Estimate the gradient of img in the direction of the first and second dimension at all points of the image, using a kernel\npadarray Generate a padded image from an array img and a specification border\nkernelfactors Prepare a factored kernel for filtering.\nfindlocalminima Returns the coordinates of elements whose value is smaller than all of their immediate neighbors\nfindlocalmaxima Returns the coordinates of elements whose value is larger than all of their immediate neighbors","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"Common kernels (filters) are organized in the Kernel and KernelFactors modules. ","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"A common task in image processing and computer vision is computing image gradients (derivatives), for which there is the dedicated function imgradients.","category":"page"},{"location":"#Examples","page":"ImageFiltering.jl","title":"Examples","text":"","category":"section"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"The most commonly used function for filtering is imfilter. Here's a simple example of linear filtering:","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"julia> using ImageFiltering, TestImages\n\njulia> img = testimage(\"mandrill\");\n\njulia> imgg = imfilter(img, Kernel.gaussian(3));\n\njulia> imgl = imfilter(img, Kernel.Laplacian());","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"When displayed, these three images look like this:","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"(Image: filterintro)","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"The padarray function can add (or remove) elements from the borders of an image, using various methods for generating any new pixels required. This example adds purple pixels on the top, left, bottom, and right edges:","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"julia> using ImageFiltering, TestImages\n\njulia> img = testimage(\"mandrill\")\n\njulia> padarray(img, Fill(colorant\"purple\", (20, 40), (60, 80)))","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"(Image: pad intro)","category":"page"},{"location":"#Feature:-arbitrary-operations-over-sliding-windows","page":"ImageFiltering.jl","title":"Feature: arbitrary operations over sliding windows","text":"","category":"section"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"This package also exports mapwindow, which allows you to pass an arbitrary function to operate on the values within a sliding window.","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"mapwindow has optimized implementations for some functions (currently, extrema).","category":"page"},{"location":"#Feature:-automatic-choice-of-FIR-or-FFT","page":"ImageFiltering.jl","title":"Feature: automatic choice of FIR or FFT","text":"","category":"section"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"For linear filtering with a finite-impulse response filtering, one can either choose a direct algorithm or one based on the fast Fourier transform (FFT).  By default, this choice is made based on kernel size. You can manually specify the algorithm using Algorithm.FFT() or Algorithm.FIR().","category":"page"},{"location":"#Feature:-Multithreading","page":"ImageFiltering.jl","title":"Feature: Multithreading","text":"","category":"section"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"If you launch Julia with JULIA_NUM_THREADS=n (where n > 1), then FIR filtering will by default use multiple threads.  You can control the algorithm by specifying a resource as defined by ComputationalResources. For example, imfilter(CPU1(Algorithm.FIR()), img, ...) would force the computation to be single-threaded.","category":"page"},{"location":"#Feature:-Models","page":"ImageFiltering.jl","title":"Feature: Models","text":"","category":"section"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"The ImageFilter.Models submodule provides predefined image-related models and its solvers that can be reused by many image processing tasks.","category":"page"},{"location":"","page":"ImageFiltering.jl","title":"ImageFiltering.jl","text":"For example, the solve_ROF_PD() function uses the primal-dual method to return a smoothed version of an image using Rudin-Osher-Fatemi (ROF) filtering, more commonly known as Total Variation (TV) denoising or TV regularization.","category":"page"}]
}
